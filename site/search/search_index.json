{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"00_introduction/","title":"Welcome to the Practical ChIP-seq Tutorial","text":"<p><code>ChIP-seq</code> <code>chromatin-immunoprecipitation</code> <code>epigenetics</code> <code>genome-wide-binding</code> <code>transcription-factors</code> <code>histone-modifications</code> <code>NGS</code> <code>introduction</code></p>"},{"location":"00_introduction/#1-what-is-chip-seq","title":"1. What is ChIP-seq?","text":"<p>ChIP-seq (Chromatin Immunoprecipitation followed by sequencing) answers one key question: Where do proteins interact with DNA in our genome?</p> <p>Think of your genome as a massive library with 3 billion books. Certain proteins act as \"bookmarks\" that control which genes are active. ChIP-seq lets us find all these bookmarks at once, across the entire genome.</p> <p>By mapping these binding locations, we learn how genes are turned on and off\u2014knowledge that is critical for understanding both normal biology and diseases like cancer.</p>"},{"location":"00_introduction/#2-a-brief-history-why-chip-seq-matters","title":"2. A Brief History &amp; Why ChIP-seq Matters","text":"<p>Before ChIP-seq, researchers had limited options for studying protein-DNA interactions. ChIP-PCR could only examine a handful of pre-selected regions\u2014like searching for a word in a book by checking only 10 pages. ChIP-chip improved on this by using microarrays, but it remained constrained to predefined genomic regions and offered limited resolution (Park, 2009).</p> <p>The arrival of next-generation sequencing in the mid-2000s changed everything. ChIP-seq enabled genome-wide, high-resolution mapping for the first time, allowing scientists to see the complete picture of protein-DNA interactions across the entire genome.</p> <p>This breakthrough enabled landmark discoveries. The ENCODE Project (2012) used ChIP-seq extensively to demonstrate that approximately 80% of the human genome has biochemical function\u2014fundamentally overturning the long-held \"junk DNA\" myth. That same year, researchers used ChIP-seq to reveal how our 24-hour body clock is encoded in chromatin, explaining at the molecular level why circadian disruption increases disease risk.</p> <p>These discoveries demonstrate ChIP-seq's direct impact on personalized medicine, cancer research, and our understanding of gene regulation.</p>"},{"location":"00_introduction/#3-how-chip-seq-works-the-experiment","title":"3. How ChIP-seq Works (The Experiment)","text":"<p>A ChIP-seq experiment captures where proteins bind to DNA through five connected steps. First, formaldehyde cross-links proteins to DNA, freezing them in place like taking a snapshot. Next, the DNA is sheared into small fragments\u2014imagine cutting a long rope into shorter segments that are easier to handle.</p> <p>The key step is immunoprecipitation: antibodies that recognize your protein of interest act like magnets, pulling out only the DNA fragments attached to that specific protein. After this enrichment, reverse cross-linking releases the DNA from the proteins, leaving you with purified DNA fragments that were bound by your target. Finally, these fragments are sequenced, generating millions of short reads that reveal the genomic locations where your protein was bound (Furey, 2012).</p>"},{"location":"00_introduction/#4-computational-analysis-pipeline","title":"4. Computational Analysis Pipeline","text":"<p>The millions of reads from Section 3 arrive as data files. Here's how we process them:</p> <pre><code>FASTQ \u2192 BAM \u2192 Peaks + BigWig\n</code></pre> <p>After sequencing, you receive data in FASTQ format\u2014a text file containing millions of short DNA sequences (= reads), each with a quality score showing how confident we are in each letter (= base call). At this stage, we don't know where in the genome these sequences came from. That's what the next step figures out.</p> <p>Alignment (= mapping) uses software like Bowtie2 to match each read to its location on a reference genome. The output is a SAM file (Sequence Alignment/Map), which records where each read landed, how well it matched, and other details.</p> <p>SAM files are plain text and take up a lot of space. So we compress them into BAM format (Binary Alignment/Map)\u2014same information, but smaller and faster to work with. In most pipelines, SAM files are never saved; the aligner writes directly to BAM.</p> <p>Next comes peak calling. Tools like MACS3 scan the BAM file and find regions where reads pile up more than expected\u2014these \"peaks\" are likely protein binding sites. The output includes peak coordinates and statistical parameters (= p-values, q-values, fold enrichment), saved as BED files and bedGraph files.</p> <p>BED files are simple lists of genomic locations (chromosome, start position, end position). They're used for many downstream tasks like finding DNA motifs or linking peaks to nearby genes (= annotation).</p> <p>bedGraph files are similar to BED files but include a fourth column: a numerical value (like signal intensity or coverage) for each region. This format is human-readable text, useful for inspection, but results in large file sizes for whole-genome data.</p> <p>BigWig files contain the same signal information as bedGraph but differ in two key ways:</p> <ol> <li>Binary format: Data is stored in compressed binary rather than plain text, reducing file size significantly</li> <li>Indexed structure: An internal index allows software to retrieve data from any genomic region without reading the entire file</li> </ol> <p>In practice, this means: when you open a bedGraph in a genome browser, the software must scan from the beginning of the file to find your region of interest. With BigWig, the software uses the index to jump directly to the relevant data block. For a 3-billion-base-pair human genome, this difference makes BigWig the standard format for visualization.</p>"},{"location":"00_introduction/#5-who-is-this-tutorial-for","title":"5. Who Is This Tutorial For?","text":"<p>This tutorial is designed for:</p> <ul> <li>Biology students new to bioinformatics</li> <li>Researchers who want hands-on ChIP-seq analysis skills</li> <li>Anyone who prefers learning by doing, not just reading</li> </ul> <p>No prior coding experience is required. We explain every step.</p>"},{"location":"00_introduction/#6-why-this-tutorial","title":"6. Why This Tutorial?","text":"<p>We built this course to solve common frustrations of bioinformatics learning. Here's what makes it different:</p>"},{"location":"00_introduction/#the-tiered-learning-method","title":"The \"Tiered\" Learning Method","text":"<p>We believe you shouldn't just run code\u2014you should understand it. Every chapter is broken into three levels:</p> Level Focus What You'll Get Level 1: Basic Concept The \"Why\" Simple explanations with real-world analogies Level 2: Execution The \"How\" Exact code to run, line-by-line Level 3: Interpretation The \"So What?\" How to read output and spot good vs. bad results <p>By the end, you'll have the skills\u2014and the code\u2014to analyze your own ChIP-seq data.</p>"},{"location":"00_introduction/#7-dataset-used-in-this-tutorial","title":"7. Dataset Used in This Tutorial","text":"<p>We use two datasets to teach different parts of the pipeline:</p>"},{"location":"00_introduction/#part-1-preprocessing-fastq-bam","title":"Part 1: Preprocessing (FASTQ \u2192 BAM)","text":"<p>Source: GSE115704 \u2014 Histone modifications in C. elegans sperm, oocytes, and early embryos.</p> <p>Why this dataset? It's publicly available and demonstrates the practical steps of downloading, organizing, and aligning raw data.</p>"},{"location":"00_introduction/#part-2-downstream-analysis-bam-peaks-visualization","title":"Part 2: Downstream Analysis (BAM \u2192 Peaks \u2192 Visualization)","text":"<p>Source: ENCODE BLaER1 data \u2014 Human cell line with ChIP-seq for CEBPA, H3K27me3, and H3K9ac.</p> <p>Why this dataset? Pre-aligned, high-quality data that lets us focus on peak calling, normalization, and comparative analysis.</p>"},{"location":"00_introduction/#lets-get-started","title":"Let's Get Started","text":"<p>You're ready to begin. In the next chapter, we'll set up your computational environment by installing the required tools.</p> <p>[!NOTE] Up Next: Before diving into analysis, we'll set up your computational environment with the bioinformatics tools you'll need throughout this tutorial.</p>"},{"location":"01_setup_environment/","title":"Setting Up Your Digital Lab Bench (Conda Environment)","text":""},{"location":"01_setup_environment/#basic-concept","title":"Basic Concept","text":"<p>Imagine you are about to start a complex experiment in a wet lab. You wouldn't just dump all your chemicals and tools onto a cluttered desk, right? You would set up a specific Lab Bench with exactly the pipettes, reagents, and machines you need for that specific experiment.</p> <p>In bioinformatics, Conda allows us to do the exact same thing on a computer.</p> <ul> <li>The Problem: Different software tools often conflict with each other (like needing different versions of Python). Installing them all on your main system is like mixing all your chemicals in one bucket\u2014messy and dangerous.</li> <li>The Solution: We create a \"Virtual Environment\" (our digital lab bench). Inside this environment, we install only the tools we need for ChIP-seq. When we are done, we can \"close\" the environment and go back to a clean computer.</li> </ul> <p>In this tutorial, we will build a simplified environment named <code>chip</code> that contains all the tools for our analysis.</p>"},{"location":"01_setup_environment/#execution","title":"Execution","text":""},{"location":"01_setup_environment/#step-1-get-the-environment-manager-anaconda","title":"Step 1: Get the Environment Manager (Anaconda)","text":"<p>First, you need the software that builds these environments. We recommend Anaconda (or the lighter version, Miniconda).</p> <ul> <li> <p>Check if you already have it:     Open your terminal and type:</p> <pre><code>conda --version\n</code></pre> <p>(If you see a version number like <code>conda 24.7.1</code>, skip to Step 2.)</p> </li> <li> <p>If not, download and install it:</p> </li> <li>Anaconda (Recommended): https://www.anaconda.com/download</li> <li>Miniconda (Lightweight): https://docs.conda.io/en/latest/miniconda.html</li> </ul>"},{"location":"01_setup_environment/#step-2-creates-the-recipe-file","title":"Step 2: Creates the \"Recipe\" File","text":"<p>To build our lab bench, we give Conda a \"recipe\" list called a YAML file. This tells Conda exactly which tools to fetch.</p> <ol> <li>Create a new file named <code>chip_env.yml</code>.</li> <li>Copy and paste the exact code below into that file:</li> </ol> <pre><code>name: chip   # Name of our environment\nchannels:    # The \"App Stores\" where we find tools\n  - bioconda\n  - conda-forge\n  - bioconda\n  - defaults\ndependencies: # The tools we want to install\n  - multiqc=1.31\n  - fastqc=0.12.1\n</code></pre> <p>Note: If you downloaded the file chip.yml . You can use that to install all the tools required for the Chip-seq analysis!</p>"},{"location":"01_setup_environment/#step-3-build-the-environment","title":"Step 3: Build the Environment","text":"<p>Now, let's look at the instructions to build the bench.</p> <ol> <li> <p>Create the environment:     Run this command in the same folder where you saved your file:</p> <pre><code>conda env create -f chip_env.yml\n</code></pre> <p>(This takes a few minutes as it downloads all the tools.)</p> </li> <li> <p>Enter the environment:     To start working, you must \"step into\" your new lab bench:</p> <pre><code>conda activate chip\n</code></pre> <p>(You should see <code>(chip)</code> appear next to your cursor in the terminal.)</p> </li> </ol>"},{"location":"01_setup_environment/#step-4-verify-your-tools","title":"Step 4: Verify Your Tools","text":"<p>Let's make sure our tools are actually there. Run these commands:</p> <pre><code># Check if key tools are reachable\nwhich fastqc\nwhich bowtie2\nwhich macs3\n\n# Check versions to ensure successful installation\nfastqc --version\nbowtie2 --version\n</code></pre> <p>If these commands print paths (like <code>/Users/.../envs/chip/bin/fastqc</code>) and version numbers, congratulations! Your digital lab bench is ready.</p>"},{"location":"01_setup_environment/#understanding-the-yaml-recipe","title":"Understanding the YAML \"Recipe\"","text":"<p>Let's break down the <code>chip_env.yml</code> file we just used:</p> <ul> <li><code>channels</code>: These are repositories (like App Stores).</li> <li><code>bioconda</code>: The community hub for bioinformatics software.</li> <li><code>conda-forge</code>: A massive collection of general-purpose tools.</li> <li>The order matters! Conda looks in the first channel on the list, then the second.</li> <li><code>dependencies</code>: This is your shopping list.</li> <li>Version Pinned (e.g., <code>bowtie2=2.5.4</code>): We specify the exact version. Why? So that if you run this analysis 2 years from now, you get the exact same results. This is key for Reproducibility.</li> </ul>"},{"location":"01_setup_environment/#managing-your-environment","title":"Managing Your Environment","text":"<p>Here are some useful \"Housekeeping\" commands:</p> Command Explanation <code>conda deactivate</code> \"Step out\" of the environment. Returns you to your base system. <code>conda env list</code> Lists all environments you have created on your computer. <code>conda env remove -n chip</code> Deletes the <code>chip</code> environment mostly used if you made a mistake and want to start over. <code>conda env update -f chip_env.yml --prune</code> Updates the environment if you change the YAML file. The <code>--prune</code> flag removes old tools you don't need anymore."},{"location":"01_setup_environment/#summary","title":"Summary","text":"<ol> <li>Analogy: We built a dedicated \"Lab Bench\" (Environment) to keep our work clean.</li> <li>Action: We used <code>conda env create</code> with a YAML recipe to install tools like Bowtie2 and MACS2.</li> <li>Result: We now have a <code>(chip)</code> environment ready for the actual ChIP-seq analysis.</li> </ol> <p>[!NOTE] Up Next: The tools are installed and waiting. Now we'll learn Bash scripting to organize and automate our bioinformatics workflow.</p>"},{"location":"02_bash_automation/","title":"Bash Automation (Your Digital Robot)","text":"<p><code>bash</code> <code>shell-scripting</code> <code>loops</code> <code>automation</code> <code>while-loops</code> <code>for-loops</code> <code>variables</code> <code>command-line</code> <code>batch-processing</code></p>"},{"location":"02_bash_automation/#introduction-why-learn-bash-for-bioinformatics","title":"Introduction: Why Learn Bash for Bioinformatics?","text":"<p>What is Bash?</p> <p>Bash is a way to control a computer using text commands instead of clicking through menus. It lets you run programs, manage files, and automate tasks by writing simple commands or scripts.</p> <p>Why is this essential for bioinformatics?</p> <p>In bioinformatics, you work with large datasets and many specialized tools that must run in a specific sequence. Bash makes these workflows repeatable by allowing you to run the same analysis on new data with one command. It keeps them transparent so you can see exactly what was done in plain text. Most importantly, Bash workflows are reliable because they're less prone to manual errors from repetitive clicking. Without Bash automation, analyses become harder to track, reproduce, and trust.</p>"},{"location":"02_bash_automation/#the-foundation-setting-up-safe-scripts","title":"The Foundation: Setting Up Safe Scripts","text":"<p>Every reliable Bash script should start with these two critical lines:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n</code></pre> <p>What do these lines do?</p> <ol> <li> <p><code>#!/bin/bash</code> \u2013 This \"shebang\" line tells your computer to use the Bash shell. It ensures your script behaves the same way on any system.</p> </li> <li> <p><code>set -euo pipefail</code> \u2013 This changes Bash's default behavior from \"keep going even if something breaks\" to \"stop immediately when an error occurs.\"</p> </li> </ol> <p>This single choice separates casual scripting from defensible scientific analysis. You want your script to fail loudly if something goes wrong, not silently produce incorrect results.</p> <p>Adding practical elements:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nmkdir -p output\necho \"Script started\"\n</code></pre> <ul> <li> <p><code>mkdir -p output</code> \u2013 Creates a directory called <code>output</code> if it doesn't exist. The <code>-p</code> flag prevents errors if the directory is already there. This establishes a predictable place for your results.</p> </li> <li> <p><code>echo \"Script started\"</code> \u2013 Prints a message to confirm the script is running. This is helpful for logging and debugging, especially when scripts run unattended.</p> </li> </ul>"},{"location":"02_bash_automation/#how-to-run-bash-scripts","title":"How to Run Bash Scripts","text":"<p>Now that you understand what goes inside a script, let's learn how to actually run it.</p>"},{"location":"02_bash_automation/#method-1-save-and-execute-recommended","title":"Method 1: Save and Execute (Recommended)","text":"<p>Step 1: Create the script file</p> <pre><code># Open a text editor (nano, vim, or any editor)\nnano my_script.sh\n</code></pre> <p>Step 2: Paste your script content</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nmkdir -p output\necho \"Script started\"\n</code></pre> <p>Step 3: Save and exit</p> <ul> <li>In <code>nano</code>: Press <code>Ctrl+O</code> (save), then <code>Ctrl+X</code> (exit)</li> <li>In <code>vim</code>: Press <code>ESC</code>, type <code>:wq</code>, press <code>Enter</code></li> </ul> <p>Step 4: Make the script executable</p> <pre><code>chmod +x my_script.sh\n</code></pre> <p>What <code>chmod +x</code> does: This command gives the file \"execute\" permission, allowing you to run it as a program.</p> <p>Step 5: Run the script</p> <pre><code>./my_script.sh\n</code></pre> <p>Why the <code>./</code> prefix? The <code>./</code> tells Bash to look for the script in the current directory.</p>"},{"location":"02_bash_automation/#method-2-using-bash-command-without-chmod","title":"Method 2: Using <code>bash</code> Command (Without chmod)","text":"<p>If you don't want to make the file executable, you can still run it:</p> <pre><code>bash my_script.sh\n</code></pre> <p>This works even without <code>chmod +x</code>, but the preferred method is still to use <code>chmod +x</code> and <code>./script.sh</code>.</p>"},{"location":"02_bash_automation/#part-1-understanding-sample-lists","title":"Part 1: Understanding Sample Lists","text":""},{"location":"02_bash_automation/#the-roll-call-analogy","title":"The \"Roll Call\" Analogy","text":"<p>Imagine grading 100 students. You don't want to type <code>\"Student_John_Doe_Homework_Final_v2.docx\"</code> every single time. You just want a simple list:</p> <ul> <li>John</li> <li>Sarah</li> <li>Mike</li> </ul> <p>In bioinformatics, we feel the same way about our sequencing files.</p> <p>The Problem:</p> <p>Our sequencing files have long, complex names like:</p> <pre><code>Control_A_H3K9ac_R1.fastq.gz\nControl_B_H3K9ac_R1.fastq.gz\n</code></pre> <p>The Goal:</p> <p>Create a clean list of sample IDs (like a \"roll call\") that we can feed into automated scripts:</p> <pre><code>Control_A_H3K9ac\nControl_B_H3K9ac\n</code></pre> <p>Why do we need this?</p> <p>This simple text file will allow our computer to automatically loop through every sample and process them one by one. Instead of typing commands 100 times, we type it once and let the loop do the work.</p>"},{"location":"02_bash_automation/#part-2-creating-your-sample-list","title":"Part 2: Creating Your Sample List","text":""},{"location":"02_bash_automation/#step-1-verify-your-files","title":"Step 1: Verify Your Files","text":"<p>Before creating any list, always check what files you actually have.</p> <pre><code>ls *.fastq.gz \n</code></pre> <p>What this does:</p> <ul> <li><code>ls</code> = \"list\" command</li> <li><code>*.fastq.gz</code> = show only files ending in <code>.fastq.gz</code></li> </ul> <p>This explicitly targets FASTQ files and is useful at the very start of any sequencing workflow (RNA-seq, ChIP-seq, ATAC-seq, CUT&amp;RUN) to quickly verify that your input files are named correctly and consistently.</p>"},{"location":"02_bash_automation/#step-2-extract-clean-sample-names","title":"Step 2: Extract Clean Sample Names","text":"<p>Now we need to remove the messy file extensions to get clean sample IDs. We'll use a tool called <code>sed</code> (Stream Editor) for this.</p>"},{"location":"02_bash_automation/#scenario-a-single-end-reads","title":"Scenario A: Single-End Reads","text":"<p>If you have single-end sequencing data , use this approach:</p>"},{"location":"02_bash_automation/#method-1-step-by-step","title":"Method 1: Step-by-step","text":"<p>This method breaks down the process into individual steps so you can see what's happening at each stage.</p> <p>Note: In real workflows, your FASTQ files are typically stored in a subdirectory like <code>raw/</code> or <code>fastq_raw/</code>. It is better to create the sample list in the <code>raw/</code> folder and copy that list to working directory</p> <p>Step 1: List all FASTQ files from the raw folder and save to a text file</p> <pre><code>cd raw/\nls *.fastq.gz &gt; samples.txt\n</code></pre> <p>This command finds all files ending in <code>.fastq.gz</code> inside the <code>raw/</code> folder and saves their names to <code>samples.txt</code>.</p> <p>Step 2: Check what got saved</p> <pre><code>cat samples.txt\n</code></pre> <p>This displays the contents of <code>samples.txt</code> so you can verify the filenames. You should see:</p> <pre><code>Control_A_H3K9ac.fastq.gz\nControl_B_H3K9ac.fastq.gz\n</code></pre> <p>Step 3: Remove the path and <code>.fastq.gz</code> extension from each line</p> <pre><code>sed 's/.fastq.gz//' samples.txt &gt; sample_id.txt\n</code></pre> <p>What this does:</p> <ul> <li>Second <code>sed 's/.fastq.gz//'</code> = Remove the <code>.fastq.gz</code> extension</li> <li><code>&gt;</code> = Redirect the final output to a new file</li> <li><code>sample_id.txt</code> = Save the cleaned names here</li> </ul> <p>Step 4: Verify the final result</p> <pre><code>cat sample_id.txt\n</code></pre> <p>Now you should see clean sample IDs without paths or extensions:</p> <pre><code>Control_A_H3K9ac\nControl_B_H3K9ac\n</code></pre>"},{"location":"02_bash_automation/#method-2-one-line-command-recommended","title":"Method 2: One-line command (recommended)","text":"<p>Once you understand the steps above, you can combine them into one efficient command:</p> <pre><code>ls *.fastq.gz |  sed 's/.fastq.gz//' &gt; sample_id.txt\n</code></pre> <p>What the pipe (<code>|</code>) does:</p> <p>Instead of saving to intermediate files, the pipe passes output directly from one command to the next:</p> <ol> <li><code>ls *.fastq.gz</code> lists the files</li> <li><code>sed</code> removes the <code>.fastq.gz</code> extension  </li> <li>Final result is saved to <code>sample_id.txt</code></li> </ol> <p>This is faster and cleaner than the step-by-step method.  Then moving the sample_id.txt to working directory.</p> <pre><code>cd ..\nmv raw/sample_id.txt .\n</code></pre>"},{"location":"02_bash_automation/#scenario-b-paired-end-reads-most-common","title":"Scenario B: Paired-End Reads (Most Common)","text":"<p>Most ChIP-seq experiments use paired-end sequencing, which produces two files per sample:</p> <pre><code>Control_A_H3K9ac_R1.fastq.gz\nControl_A_H3K9ac_R2.fastq.gz\nControl_B_H3K9ac_R1.fastq.gz\nControl_B_H3K9ac_R2.fastq.gz\n</code></pre> <p>The challenge: We don't want <code>Control_A_H3K9ac</code> to appear twice in our list. We only want each sample name once.</p> <p>The solution: Target only the <code>_R1</code> files.</p> <pre><code>ls *_R1.fastq.gz | sed 's/_R1.fastq.gz//' &gt; sample_id.txt\n</code></pre> <p>Why look for R1?</p> <p>By listing only the <code>_R1</code> files, we get exactly one entry per sample. We then strip off the <code>_R1.fastq.gz</code> suffix to get the clean sample name.</p> <p>The script will automatically know to look for both <code>_R1</code> and <code>_R2</code> files later when we use this list.</p>"},{"location":"02_bash_automation/#part-3-using-your-sample-list-in-automation","title":"Part 3: Using Your Sample List in Automation","text":"<p>Now that we have <code>sample_id.txt</code>, we can use it to automate processing of all samples.</p>"},{"location":"02_bash_automation/#understanding-the-concept","title":"Understanding the Concept","text":"<p>Since we know the sample ID (e.g., <code>Control_A_H3K9ac</code>), we can tell our script:</p> <p>\"For each sample ID, look for two files: the sample name plus <code>_R1.fastq.gz</code> and the sample name plus <code>_R2.fastq.gz</code>\"</p> <p>The computer can construct these filenames automatically.</p>"},{"location":"02_bash_automation/#example-1-basic-loop-to-verify-file-pairs","title":"Example 1: Basic Loop to Verify File Pairs","text":"<p>This script reads your sample list and prints out the paired filenames:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nwhile read -r sample; do\n  echo \"sample_id: $sample\"\n\n  fq1=\"${sample}_R1.fastq.gz\"\n  fq2=\"${sample}_R2.fastq.gz\"\n\n  echo \"paired end: $fq1 : $fq2\"\ndone &lt; sample_id.txt\n</code></pre> <p>Output:</p> <pre><code>sample_id: Control_A_H3K9ac\npaired end:  Control_A_H3K9ac_R1.fastq.gz  :  Control_A_H3K9ac_R2.fastq.gz\n\nsample_id: Control_B_H3K9ac\npaired end:    Control_B_H3K9ac_R1.fastq.gz  :  Control_B_H3K9ac_R2.fastq.gz\n</code></pre> <p>What this script does:</p> <ul> <li><code>while read -r sample</code> \u2013 Reads one line (sample ID) at a time from <code>sample_id.txt</code></li> <li><code>fq1=\"${sample}_R1.fastq.gz\"</code> \u2013 Constructs the forward read filename</li> <li><code>fq2=\"${sample}_R2.fastq.gz\"</code> \u2013 Constructs the reverse read filename</li> <li><code>echo</code> \u2013 Prints the results so you can verify</li> </ul>"},{"location":"02_bash_automation/#example-2-adding-directory-paths","title":"Example 2: Adding Directory Paths","text":"<p>In real workflows, your raw FASTQ files are usually in a specific folder. Let's account for that:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nRAW_DIR=\"fastq_raw\"\n\nwhile read -r sample; do\n  echo \"sample_id: $sample\"\n\n  fq1=\"${RAW_DIR}/${sample}_R1.fastq.gz\"\n  fq2=\"${RAW_DIR}/${sample}_R2.fastq.gz\"\n\n  echo \"inputs:\"\n  echo \"  $fq1\"\n  echo \"  $fq2\"\n\ndone &lt; sample_id.txt\n</code></pre> <p>Output:</p> <pre><code>sample_id: Control_A_H3K9ac\ninputs:\n  fastq_raw/Control_A_H3K9ac_R1.fastq.gz\n  fastq_raw/Control_A_H3K9ac_R2.fastq.gz\n\nsample_id: Control_B_H3K9ac\ninputs:\n  fastq_raw/Control_B_H3K9ac_R1.fastq.gz\n  fastq_raw/Control_B_H3K9ac_R2.fastq.gz\n</code></pre> <p>Key change:</p> <ul> <li><code>RAW_DIR=\"fastq_raw\"</code> \u2013 Defines where your input files are located</li> <li><code>${RAW_DIR}/${sample}_R1.fastq.gz</code> \u2013 Constructs the full path to each file</li> </ul>"},{"location":"02_bash_automation/#example-3-complete-workflow-with-input-and-output-directories","title":"Example 3: Complete Workflow with Input and Output Directories","text":"<p>This example shows a real bioinformatics workflow pattern: reading files from an input directory and writing results to an output directory.</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nRAW_DIR=\"fastq_raw\"\nOUT_DIR=\"bowtie_align\"\n\nmkdir -p \"$OUT_DIR\"\n\nwhile read -r sample; do\n  echo \"sample_id: $sample\"\n\n  fq1=\"${RAW_DIR}/${sample}_R1.fastq.gz\"\n  fq2=\"${RAW_DIR}/${sample}_R2.fastq.gz\"\n  bam=\"${OUT_DIR}/${sample}.sorted.bam\"\n\n  echo \"inputs:\"\n  echo \"  $fq1\"\n  echo \"  $fq2\"\n\n  echo \"output:\"\n  echo \"  $bam\"\n\n  echo \"bowtie2 command: bowtie2 -x hg38_index -1 $fq1 -2 $fq2 | samtools sort -o $bam\"\n  echo\ndone &lt; sample_id.txt\n</code></pre> <p>Understanding the directory structure:</p> <p>This script follows a crucial bioinformatics principle: separate input data from output results.</p> <ul> <li>Input directory (<code>RAW_DIR=\"fastq_raw\"</code>): Where your raw sequencing files are stored. This should be read-only to preserve original data.</li> <li>Output directory (<code>OUT_DIR=\"bowtie_align\"</code>): Where processed results will be saved. Created automatically if it doesn't exist.</li> </ul> <p>Breaking down the script:</p> <ol> <li> <p><code>mkdir -p \"$OUT_DIR\"</code> \u2013 Creates the output directory before processing starts. The <code>-p</code> flag means \"don't error if it already exists.\"</p> </li> <li> <p>Input file construction:</p> </li> <li><code>fq1=\"${RAW_DIR}/${sample}_R1.fastq.gz\"</code> \u2013 Forward reads from the raw data folder</li> <li> <p><code>fq2=\"${RAW_DIR}/${sample}_R2.fastq.gz\"</code> \u2013 Reverse reads from the raw data folder</p> </li> <li> <p>Output file construction:</p> </li> <li> <p><code>bam=\"${OUT_DIR}/${sample}.sorted.bam\"</code> \u2013 Aligned, sorted BAM file will go in the output folder</p> </li> <li> <p>The command preview:</p> </li> <li>Shows what the actual bowtie2 alignment command would be</li> <li><code>bowtie2 -x hg38_index</code> \u2013 Uses the human genome reference</li> <li><code>-1 $fq1 -2 $fq2</code> \u2013 Paired-end input files</li> <li><code>| samtools sort -o $bam</code> \u2013 Pipes output to samtools to create sorted BAM</li> </ol> <p>Output:</p> <pre><code>sample_id: Control_A_H3K9ac\ninputs:\n  fastq_raw/Control_A_H3K9ac_R1.fastq.gz\n  fastq_raw/Control_A_H3K9ac_R2.fastq.gz\noutput:\n  bowtie_align/Control_A_H3K9ac.sorted.bam\nbowtie2 command: bowtie2 -x hg38_index -1 fastq_raw/Control_A_H3K9ac_R1.fastq.gz -2 fastq_raw/Control_A_H3K9ac_R2.fastq.gz | samtools sort -o bowtie_align/Control_A_H3K9ac.sorted.bam\n\nsample_id: Control_B_H3K9ac\ninputs:\n  fastq_raw/Control_B_H3K9ac_R1.fastq.gz\n  fastq_raw/Control_B_H3K9ac_R2.fastq.gz\noutput:\n  bowtie_align/Control_B_H3K9ac.sorted.bam\nbowtie2 command: bowtie2 -x hg38_index -1 fastq_raw/Control_B_H3K9ac_R1.fastq.gz -2 fastq_raw/Control_B_H3K9ac_R2.fastq.gz | samtools sort -o bowtie_align/Control_B_H3K9ac.sorted.bam\n</code></pre> <p>Why organize this way?</p> <p>This directory structure keeps your project clean and organized:</p> <pre><code>your_project/\n\u251c\u2500\u2500 fastq_raw/              \u2190 Original data (never modified)\n\u2502   \u251c\u2500\u2500 Control_A_H3K9ac_R1.fastq.gz\n\u2502   \u251c\u2500\u2500 Control_A_H3K9ac_R2.fastq.gz\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 bowtie_align/           \u2190 Alignment results (can regenerate)\n\u2502   \u251c\u2500\u2500 Control_A_H3K9ac.sorted.bam\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 sample_id.txt           \u2190 Sample list\n\u2514\u2500\u2500 analysis_script.sh      \u2190 This script\n</code></pre> <p>If something goes wrong with alignment, you can safely delete the <code>bowtie_align/</code> folder and rerun the script without touching your original raw data.</p> <p>Best Practice: Separate Folders for Each Process</p> <p>In real ChIP-seq analysis, you should create a separate output folder for each processing step and file type. This keeps your project organized and makes troubleshooting easier. A typical ChIP-seq project might have folders like:</p> <ul> <li><code>fastq_raw/</code> - Original FASTQ files from sequencing</li> <li><code>fastqc_reports/</code> - Quality control reports</li> <li><code>trimmed_fastq/</code> - Adapter-trimmed reads (if needed)</li> <li><code>bowtie_align/</code> - Aligned BAM files</li> <li><code>dedup_bam/</code> - Deduplicated BAM files</li> <li><code>peaks/</code> - Peak calling results from MACS2</li> <li><code>bigwig/</code> - Coverage tracks for genome browsers</li> <li><code>qc_metrics/</code> - deepTools quality metrics</li> </ul> <p>This folder structure makes it easy to: (1) track which processing stage created which files, (2) quickly find the data you need, (3) delete and regenerate intermediate files without affecting earlier steps, and (4) share your work with collaborators who can immediately understand your project organization.</p>"},{"location":"02_bash_automation/#summary","title":"Summary","text":"<p>What you learned:</p> <ol> <li>Safe scripting: Start every script with <code>#!/bin/bash</code> and <code>set -euo pipefail</code></li> <li>Sample list creation: Use <code>ls</code> and <code>sed</code> to extract clean sample IDs from messy filenames</li> <li>Single-end: <code>ls *.fastq.gz | sed 's/.fastq.gz//' &gt; sample_id.txt</code></li> <li>Paired-end: <code>ls *_R1.fastq.gz | sed 's/_R1.fastq.gz//' &gt; sample_id.txt</code></li> <li>Automation: Use <code>while read</code> loops to process all samples automatically</li> </ol> <p>The key insight: This simple text file (<code>sample_id.txt</code>) acts as a \"roll call\" or \"attendance sheet\" for your entire analysis pipeline. It's the foundation that makes large-scale automation possible.</p> <p>[!NOTE] Up Next: Now that you understand Bash automation, we'll use these skills to download real ChIP-seq data from public databases.</p>"},{"location":"03_geo_fastq_download/","title":"Getting the Raw Data (FASTQ)","text":"<p><code>GEO</code> <code>SRA</code> <code>FASTQ</code> <code>fasterq-dump</code> <code>sra-toolkit</code> <code>data-download</code> <code>sequencing-data</code> <code>NCBI</code> <code>public-datasets</code></p> <p>[!NOTE] Reminder: While this tutorial teaches you how to download data from SRA, our focus is on SRA data.</p>"},{"location":"03_geo_fastq_download/#level-1-basic-concept","title":"Level 1: Basic Concept","text":""},{"location":"03_geo_fastq_download/#the-library-analogy","title":"The \"Library\" Analogy","text":"<p>Before we download anything, it helps to understand where the data lives. Think of the public databases like a University Library.</p> <ul> <li>GEO (Gene Expression Omnibus): This is the Card Catalog. It has the descriptions (Metadata) of the experiments\u2014like \"H3K27ac in Breast Cancer\"\u2014but it usually doesn't hold the actual heavy books (data files).</li> <li>SRA (Sequence Read Archive) &amp; ENA (European Nucleotide Archive): These are the Stacks. This is where the actual raw data files are stored.</li> </ul> <p>Your Goal: You find an interesting study in the Catalog (GEO), get its ID, and then send a runner (our software tool) to the Stacks (SRA/ENA) to fetch the files.</p>"},{"location":"03_geo_fastq_download/#the-files-you-will-encounter","title":"The Files You Will Encounter","text":"<ol> <li>FASTQ (Raw Reads):</li> <li>BAM (Aligned Reads):</li> <li>BED/BigWig (Signals):</li> </ol>"},{"location":"03_geo_fastq_download/#level-2-fetching-the-data","title":"Level 2: Fetching the data","text":"<p>Complete information for all sequencing runs associated with this repository is available through the NCBI SRA Run Selector (PRJNA475794). The Run Selector provides an interactive interface to inspect sequencing metadata, including library layout, platform, read length, and experimental design.</p> <p>From this interface, you can download the full metadata table as well as a plain accession list containing the SRR identifiers. The accession list can be saved as <code>srr_list.txt</code> and used directly for automated data retrieval. Unwanted runs can be removed from this file before download, allowing precise control over which datasets are processed.</p> <p></p> <p>To download data, we use a tool called fastq-dl. It acts like a smart librarian\u2014you just give it the ID number, and it deals with the complicated databases for you.</p>"},{"location":"03_geo_fastq_download/#21-download-a-single-sample","title":"2.1 Download a Single Sample","text":"<p>If you have a Run ID (starts with SRR or ERR), use this command:</p> <pre><code># Download H3K27me3 IP replicate 1\nfastq-dl --accession SRR7297996 --provider SRA --cpus 4\n\n# Or from ENA (often faster/more reliable)\nfastq-dl --accession SRR7297996 --provider ena\n</code></pre>"},{"location":"03_geo_fastq_download/#22-download-multiple-samples-the-loop","title":"2.2 Download Multiple Samples (The Loop)","text":"<p>Usually, you need to download many samples. Instead of typing the command 10 times, we put the IDs in a list.</p> <ol> <li> <p>Create a file named <code>srr_list.txt</code> with one ID per line:</p> <pre><code>SRR7297996\nSRR7297997\nSRR7298011\nSRR7298012\n</code></pre> </li> <li> <p>Run this \"Loop\" to download them one by one:</p> </li> </ol> <pre><code>#!/bin/bash\nset -euo pipefail\n\nRAW_DIR=\"fastq_raw\"\nmkdir -p \"$RAW_DIR\"\n\nwhile read -r acc; do\n  echo \"Downloading accession: $acc\"\n\n  fastq-dl \\\n    --accession \"$acc\" \\\n    --provider SRA \\\n    --cpus 1 \\\n    --outdir \"$RAW_DIR\"\n\n  echo \"Finished downloading: $acc\"\ndone &lt; srr_list.txt\n</code></pre>"},{"location":"03_geo_fastq_download/#23-parallel-download-the-fast-way","title":"2.3 Parallel Download (The Fast Way)","text":"<p>If you have a powerful computer, you can download multiple files at the same time using <code>parallel</code>.</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nmkdir -p fastq_raw\n\nparallel -j 4 \\\n  'echo \"Starting download: {}\" &amp;&amp;\n   fastq-dl --accession {} --provider SRA --cpus 1 --outdir fastq_raw &amp;&amp;\n   echo \"Finished download: {}\"' \\\n  :::: srr_list.txt\n</code></pre> <p>Directory structure after download:</p> <pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 fastq_raw/                    \u2190 Downloaded files from SRA/ENA\n\u2502   \u251c\u2500\u2500 SRR7297996.fastq.gz\n\u2502   \u251c\u2500\u2500 SRR7297997.fastq.gz\n\u2502   \u251c\u2500\u2500 SRR7298011.fastq.gz\n\u2502   \u251c\u2500\u2500 SRR7298012.fastq.gz\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 srr_list.txt                  \u2190 SRR ID list used for download\n</code></pre>"},{"location":"03_geo_fastq_download/#23-renaming-downloaded-files","title":"2.3: Renaming Downloaded Files","text":"<p>After downloading, the files will have generic SRR IDs as names. It's best practice to rename them to biological sample names based on the metadata:</p> <p>Sample Mapping Table:</p> SRR ID Sample Type Descriptive Name SRR7297996 H3K27me3 IP H3K27me3_IP_rep1 SRR7297997 H3K27me3 IP H3K27me3_IP_rep2 SRR7298011 Input control Input_rep1 SRR7298012 Input control Input_rep2 <p>Renaming Script:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\ncd fastq_raw/\n\n# Rename SRR7297996 (H3K27me3 IP rep1)\nmv SRR7297996.fastq.gz H3K27me3_IP_rep1.fastq.gz\n\n# Rename SRR7297997 (H3K27me3 IP rep2)\nmv SRR7297997.fastq.gz H3K27me3_IP_rep2.fastq.gz\n\n# Rename SRR7298011 (Input rep1)\nmv SRR7298011.fastq.gz Input_rep1.fastq.gz\n\n# Rename SRR7298012 (Input rep2)\nmv SRR7298012.fastq.gz Input_rep2.fastq.gz\n\necho \"Renaming complete!\"\n</code></pre>"},{"location":"03_geo_fastq_download/#24-creating-sample-id-list","title":"2.4: Creating Sample ID List","text":"<p>After renaming, create <code>sample_id.txt</code> with clean sample names for downstream automation:</p> <pre><code># Create sample_id.txt from renamed files\ncd fastq_raw/\nls *.fastq.gz | sed 's/.fastq.gz//' &gt; ../sample_id.txt\n\ncd ..\nmv fastq_raw/sample_id.txt .\ncat sample_id.txt\n</code></pre> <p>Contents of <code>sample_id.txt</code>:</p> <pre><code>H3K27me3_IP_rep1\nH3K27me3_IP_rep2\nInput_rep1\nInput_rep2\n</code></pre> <p>This file will be used in all downstream automation loops (QC, alignment, deduplication, etc.).</p> <p>Directory structure after renaming:</p> <pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 fastq_raw/                    \u2190 Renamed FASTQ files\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.fastq.gz\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep2.fastq.gz\n\u2502   \u251c\u2500\u2500 Input_rep1.fastq.gz\n\u2502   \u2514\u2500\u2500 Input_rep2.fastq.gz\n\u251c\u2500\u2500 srr_list.txt                  \u2190 Original SRR ID list\n\u2514\u2500\u2500 sample_id.txt                 \u2190 Clean sample names for automation\n</code></pre>"},{"location":"03_geo_fastq_download/#24-download-an-entire-study","title":"2.4 Download an Entire Study","text":"<p>You can also download everything associated with a study ID (starts with SRP or PRJNA):</p> <pre><code>fastq-dl --accession SRP115709\n</code></pre> <p>Note: Be careful! A whole study might have hundreds of files.</p>"},{"location":"03_geo_fastq_download/#connecting-geo-to-sra","title":"Connecting GEO to SRA","text":"<p>How do we find the SRR numbers? In GEO, you will see a hierarchy. It's important not to mix these up:</p> Level Prefix (SRA / ENA) What It Is Project PRJNA / PRJEB The umbrella project (e.g., \"Breast Cancer Epigenomics 2024\"). Study SRP / ERP A specific paper or dataset. Sample SRS / ERS The biological sample (e.g., \"Patient 5 Tumor\"). Experiment SRX / ERX The library prep info. Run SRR / ERR The actual data. This is what you download."},{"location":"03_geo_fastq_download/#technical-replicates-multi-lane","title":"Technical Replicates (Multi-lane)","text":"<p>Sometimes, one biological sample is sequenced across multiple \"lanes\" of a machine to get more reads.</p> <ul> <li>Result: You might see <code>SRR900100</code> and <code>SRR900101</code> for the same sample.</li> <li>Action: <code>fastq-dl</code> will download them. Later, we will merge these FASTQ files together so we have one big file for that sample.</li> </ul>"},{"location":"03_geo_fastq_download/#summary","title":"Summary","text":"<ol> <li>Understand: GEO is for metadata; SRA/ENA is for data.</li> <li>Identify: Find the SRR (Run) IDs for your samples.</li> <li>Download: Use <code>fastq-dl</code> with a loop or parallel command to fetch the FASTQ files.</li> </ol> <p>[!NOTE] Up Next: The FASTQ files are now available. We proceed with read inspection, quality control, and trimming.</p>"},{"location":"04_fastq_concepts/","title":"Understanding and Cleaning Your Data (FASTQ &amp; fastp)","text":"<p><code>FASTQ-format</code> <code>fastp</code> <code>quality-control</code> <code>adapter-trimming</code> <code>Phred-scores</code> <code>read-filtering</code> <code>QC-reports</code> <code>quality-assessment</code></p>"},{"location":"04_fastq_concepts/#1-basic-concept-the-anatomy-of-a-read","title":"1: Basic Concept (The Anatomy of a Read)","text":"<p>A FASTQ file is just a text file full of DNA sequences. But unlike a simple list of letters, every single read carries extra baggage (its quality score).</p> <p>Think of every read like a Luggage Tag with 4 lines of information:</p> <ol> <li>Line 1 (The Header): Starts with <code>@</code>. This is the ID Card. It tells you the machine name, flowcell lane, and coordinates.</li> <li>Line 2 (The Sequence): The DNA letters (<code>ACTG...</code>). This is the Content inside the bag.</li> <li>Line 3 (The Spacer): Starts with <code>+</code>. Just a divider.</li> <li>Line 4 (The Quality): A string of weird characters (<code>F:F#,,...</code>). This is the Trust Score. Each character represents the probability that the corresponding base in Line 2 is wrong.</li> </ol> <p>Example Read:</p> <pre><code>@SN227:495:CA0TUACXX:1:1106:1159:2114 1:N:0:ATCACG  &lt;-- ID: Read #1\nGTAAAAAGATTACATATATATTTAAAGTACACTGTAATTCTTANCA    &lt;-- DNA: \"N\" means the machine failed to call that base\n+                                                  &lt;-- Spacer\nFDFFFHHHHHJIJGIJIJJHJJJJJJIIJIJGIHFIIJJIIIIJG        &lt;-- Quality: Each character encodes a Phred quality score (Illumina 1.8+, ASCII offset 33).\n</code></pre>"},{"location":"04_fastq_concepts/#level-2-execution-the-car-wash","title":"Level 2: Execution (The Car Wash)","text":"<p>Before we start analyzing, we need to clean our data.</p> <ul> <li>The Problem: Sequencers sometimes make mistakes, especially at the ends of reads. They also leave \"adapters\" (artificial tags) attached to the DNA.</li> <li>The Solution: We use a tool called fastp. It acts like an automatic car wash: dirty reads go in, clean reads come out.</li> </ul>"},{"location":"04_fastq_concepts/#21-basic-cleaning-single-end","title":"2.1 Basic Cleaning (Single-End)","text":"<pre><code># -i: Input (dirty)\n# -o: Output (clean)\nfastp -i fastq_raw/H3K27me3_IP_rep1.fastq.gz -o fastq_cleaned/H3K27me3_IP_rep1.clean.fastq.gz\n</code></pre> <p>[!NOTE] This dataset uses single-end sequencing. If you have paired-end data, you would use:</p> <pre><code>fastp -i in.R1.fq.gz -I in.R2.fq.gz -o out.R1.fq.gz -O out.R2.fq.gz\n</code></pre> <p>What does fastp do automatically?</p> <ul> <li>Quality Filtering: Drops reads if too many bases have low scores (default: Phred -q &lt; 15).</li> <li>Length Filtering: Drops reads that become too short after trimming (default: -l &lt; 15bp).</li> <li>Adapter Removal: Finds and cuts off adapter sequences automatically.</li> </ul>"},{"location":"04_fastq_concepts/#level-3-advanced-analysis-the-math","title":"Level 3: Advanced Analysis (The Math)","text":""},{"location":"04_fastq_concepts/#31-quick-stats-with-awk","title":"3.1 Quick Stats with AWK","text":"<p>Sometimes you don't want to run a full report; you just want to know \"How many reads do I have?\" You can use <code>awk</code> (a math tool for text) to count directly from the compressed file.</p> <p>Count Total Reads:</p> <pre><code># A FASTQ record is 4 lines. We count total lines and divide by 4.\ngzcat fastq_raw/H3K27me3_IP_rep1.fastq.gz | wc -l | awk '{print $1/4 \" reads\"}'\n</code></pre> <p>Count Total Bases (Coverage):</p> <pre><code># Sums the length of line 2 (sequence) for every record\ngzcat fastq_raw/H3K27me3_IP_rep1.fastq.gz | awk 'NR%4==2 {b+=length($0)} END{print b \" bases\"}'\n</code></pre> <ul> <li>Approximation: If you have 100 Million bases and your genome is 3 Billion bases (Human), your coverage is roughly 0.03x.</li> </ul>"},{"location":"04_fastq_concepts/#32-batch-processing","title":"3.2 Batch Processing","text":"<p>If you have 50 files, you can use a script to run <code>fastp</code> on all of them in parallel. The <code>fastp</code> developers provide a handy script called  parallel.py:</p> <pre><code># Process 3 files at a time (-f 3), using 2 threads per file (-t 2)\npython parallel.py -i /fastq_raw -o /fastq_cleaned -r /fastp_reports -f 3 -t 2\n</code></pre> <p>Parameter explanation:</p> <ul> <li><code>-f 3</code>: Sets the batch size\u2014the script processes 3 files at a time</li> <li><code>-t 2</code>: Sets the number of threads per file\u2014each file is processed with 2 threads</li> </ul> <p>This automatically finds pairs and generates HTML reports for every sample.</p> <p>[!IMPORTANT] parallel.py avoids the need to explicitly loop over <code>sample_id.txt</code> in a Bash script.</p> <pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 fastq_raw/                  # Original FASTQ files\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.fastq.gz\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep2.fastq.gz\n\u2502   \u2514\u2500\u2500 Input_rep1.fastq.gz\n\u251c\u2500\u2500 fastq_cleaned/              # Cleaned FASTQ files\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.clean.fastq.gz\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep2.clean.fastq.gz\n\u2502   \u2514\u2500\u2500 Input_rep1.clean.fastq.gz\n\u251c\u2500\u2500 fastp_reports/              # HTML QC reports\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.html\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep2.html\n\u2502   \u2514\u2500\u2500 Input_rep1.html\n\u2514\u2500\u2500 sample_id.txt\n</code></pre>"},{"location":"04_fastq_concepts/#summary","title":"Summary","text":"<ol> <li>Understand: FASTQ files have 4 lines per read; line 4 is the quality score.</li> <li>Action: Always run <code>fastp</code> to trim adapters, low-quality bases, and too-short reads.</li> <li>Check: Use <code>wc -l</code> or <code>awk</code> for instant feedback on your data size.</li> </ol> <p>[!NOTE] Up Next: With clean reads in hand, we're ready to align them to a reference genome using Bowtie2.</p>"},{"location":"05_alignment_bowtie2/","title":"Alignment (Solving the Jigsaw Puzzle)","text":"<p><code>Bowtie2</code> <code>alignment</code> <code>BAM-files</code> <code>single-end</code> <code>paired-end</code> <code>samtools</code> <code>genome-index</code> <code>MAPQ</code> <code>quality-control</code> <code>multimapping</code> <code>ChIP-seq</code> <code>flagstat</code> <code>MultiQC</code> <code>filtering</code></p>"},{"location":"05_alignment_bowtie2/#basic-concept-the-puzzle","title":"Basic Concept (The \"Puzzle\")","text":"<p>Imagine your Reference Genome is the Picture on the Puzzle Box (a complete image of the DNA). Your Reads (FASTAS) are the millions of tiny Puzzle Pieces scattered on the floor.</p> <p>Alignment is simply picking up every piece and finding exactly where it fits on the picture.</p> <ul> <li>The Input: Millions of jumbled reads.</li> <li>The Tool: Bowtie2 (The Puzzle Solver).</li> <li>The Output: A BAM File. This is the digital record of where every piece belongs.</li> </ul>"},{"location":"05_alignment_bowtie2/#execution-solving-it","title":"Execution (Solving It)","text":""},{"location":"05_alignment_bowtie2/#step-1-the-index-building-the-map","title":"Step 1: The Index (Building the Map)","text":"<p>Before Bowtie2 can work, it needs to process the reference genome into a format it can search quickly. This is called an Index.</p> <pre><code># Example syntax: bowtie2-build [genome.fa] [prefix_name]\nbowtie2-build genome_index/ce.fa genome_index/ce_index            # ce.fa = C. elegans reference genome\n</code></pre> <p>You only do this once!</p> <p>You can download the C. elegans reference genome from Ensembl using the following link:  C. elegans genome.  Place it in the genome_index directory, decompress it, and rename the file to <code>ce.fa</code></p>"},{"location":"05_alignment_bowtie2/#after-indexing-bowtie2","title":"After Indexing (Bowtie2)","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 fastq_raw/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 fastq_cleaned/                \u2190 Fastp cleaned reads\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 fastp_reports/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 genome_index/           \u2190 Bowtie2 index files\n\u2502   \u251c\u2500\u2500 ce_index.1.bt2\n\u2502   \u251c\u2500\u2500 ce_index.2.bt2\n\u2502   \u251c\u2500\u2500 ce_index.3.bt2\n\u2502   \u251c\u2500\u2500 ce_index.4.bt2\n\u2502   \u251c\u2500\u2500 ce_index.rev.1.bt2\n\u2502   \u2514\u2500\u2500 ce_index.rev.2.bt2\n\u2514\u2500\u2500 sample_id.txt\n</code></pre>"},{"location":"05_alignment_bowtie2/#step-2-single-sample-alignment","title":"Step 2: Single Sample Alignment","text":"<p>Run Bowtie2 alignment for a single-end sample</p> <p>Input files needed:</p> <ul> <li>Reference genome index: <code>genome_index/ce_index</code> (created in previous step)</li> <li>Cleaned FASTQ file: <code>fastq_cleaned/H3K27me3_IP_rep1.clean.fastq.gz</code></li> </ul> <pre><code>mkdir -p bowalign\n\nbowtie2 -x genome_index/ce_index \\\n  -U fastq_cleaned/H3K27me3_IP_rep1.clean.fastq.gz \\\n  -p 6 --no-unal \\\n  2&gt; bowalign/H3K27me3_IP_rep1.log | \\\n  samtools sort -@ 6 -o bowalign/H3K27me3_IP_rep1.sorted.bam\n\nsamtools index bowalign/H3K27me3_IP_rep1.sorted.bam\n</code></pre> <p>What this does:</p> <ol> <li>bowtie2 aligns reads to the reference genome using the <code>-U</code> flag for single-end data</li> <li>-p 6 uses 6 CPU threads for faster processing</li> <li>--no-unal suppresses unaligned reads from output (reads that don't match the genome are excluded, saving disk space and processing time downstream)</li> <li>2&gt; saves alignment statistics to a log file</li> <li>samtools sort sorts alignments by genomic position (required for downstream analysis)</li> <li>samtools index creates an index file (.bai) for fast random access</li> </ol> <p>[!NOTE] If you have paired-end data, use <code>-1</code> and <code>-2</code> flags instead of <code>-U</code>:</p> <pre><code>bowtie2 -x genome_index/ce_index \\\n  -1 fastq_cleaned/Sample_R1.clean.fastq.gz \\\n  -2 fastq_cleaned/Sample_R2.clean.fastq.gz \\\n  -p 6 --no-unal \\\n  2&gt; bowalign/Sample.log | samtools sort -@ 6 -o bowalign/Sample.sorted.bam\n\nsamtools index bowalign/Sample.sorted.bam\n</code></pre> <p>Final Touch: We always \"index\" the BAM file. Think of this as creating a Table of Contents so the computer can jump to any chromosome instantly.</p> <pre><code>samtools index bowalign/H3K27me3_IP_rep1.sorted.bam\n</code></pre>"},{"location":"05_alignment_bowtie2/#output-structure","title":"Output Structure","text":"<p>After running this step, your directory should look like:</p> <pre><code>bowalign/\n\u251c\u2500\u2500 H3K27me3_IP_rep1.log\n\u251c\u2500\u2500 H3K27me3_IP_rep1.sorted.bam\n\u2514\u2500\u2500 H3K27me3_IP_rep1.sorted.bam.bai\n</code></pre> <p>Once this single run completes successfully, you can confidently automate for all samples.</p>"},{"location":"05_alignment_bowtie2/#step-3-automation-loop","title":"Step 3: Automation Loop","text":"<p>After creating <code>sample_id.txt</code> (see Section 2.4), here is the script to run this for all your samples:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nmkdir -p bowalign bowalign_log\n\nwhile read -r sample; do\n  echo \"Aligning $sample\"\n\n  bowtie2 -x genome_index/ce_index \\\n    -U \"fastq_cleaned/${sample}.clean.fastq.gz\" \\\n    -p 6 --no-unal \\\n    2&gt; \"bowalign_log/${sample}.bowtie2.log\" \\\n    | samtools sort -@ 6 -o \"bowalign/${sample}.sorted.bam\"\n\n  samtools index \"bowalign/${sample}.sorted.bam\"\n\ndone &lt; sample_id.txt\n</code></pre> <p>[!NOTE] Paired-end while loop (if your samples have _R1 and_R2 files):</p> <pre><code>while read -r sample; do\n  echo \"Aligning $sample\"\n\n  bowtie2 -x genome_index/ce_index \\\n    -1 \"fastq_cleaned/${sample}_R1.clean.fastq.gz\" \\\n    -2 \"fastq_cleaned/${sample}_R2.clean.fastq.gz\" \\\n    -p 6 --no-unal \\\n    2&gt; \"bowalign_log/${sample}.log\" | \\\n  samtools sort -@ 6 -o \"bowalign/${sample}.sorted.bam\"\n\n  samtools index \"bowalign/${sample}.sorted.bam\"\n\ndone &lt; sample_id.txt\n</code></pre>"},{"location":"05_alignment_bowtie2/#optimization","title":"Optimization","text":""},{"location":"05_alignment_bowtie2/#optimization-threads-vs-jobs","title":"Optimization: Threads vs. Jobs","text":"<p>You have a limited number of CPU cores (computers brains). You can use them in two ways:</p> <ol> <li>Multi-Threading (<code>-p 6</code>): One sample uses 6 cores. It finishes very fast, but you only do one sample at a time.<ul> <li>Best for: Large genomes, low memory.</li> </ul> </li> <li>Parallel Jobs: You run 3 samples at once, and each sample uses 2 cores.<ul> <li>Best for: Many small samples (RNA-seq, small genomes).</li> </ul> </li> </ol> <p>Rule of Thumb: <code>bowtie2</code> stops getting faster after about 8 threads. Don't give it 50 threads; it's a waste!</p> <p>Benchmarking Bowtie2 Threading - Jeff Kaufman (2023)</p> <p>BOWTIE2 - HPCC Wiki</p> <p>Guidance with using multiple threads with samtools - GitHub</p> <p>Example with GNU Parallel:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nmkdir -p bowalign bowalign_log\n\nparallel -j 2 '\n  bowtie2 \\\n    -x genome_index/ce_index \\\n    -U fastq_cleaned/{}.clean.fastq.gz \\\n    -p 4 \\\n    --no-unal \\\n    2&gt; bowalign_log/{}.log \\\n  | samtools sort \\\n      -@ 2 \\\n      -m 1G \\\n      -o bowalign/{}.sorted.bam\n\n  samtools index bowalign/{}.sorted.bam\n' :::: sample_id.txt\n</code></pre> <p>Effective CPU usage (implied by this setup):</p> <ul> <li>2 parallel samples (<code>-j 2</code>)</li> <li>Per sample: bowtie2 (4 threads, <code>-p 4</code>) + samtools sort (2 threads, <code>-@ 2</code>)</li> <li>Total \u2248 12 threads \u2192 safe on a 16-core machine</li> </ul> <pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 fastq_raw/\n\u251c\u2500\u2500 fastq_cleaned/\n\u251c\u2500\u2500 fastp_reports/\n\u251c\u2500\u2500 genome_index/\n\u251c\u2500\u2500 bowalign/                \u2190 Aligned BAM files\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.sorted.bam\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.sorted.bam.bai\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 bowalign_log/            \u2190 Alignment statistics\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.log\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 sample_id.txt\n</code></pre>"},{"location":"05_alignment_bowtie2/#understanding-bam-file-structure","title":"Understanding BAM File Structure","text":"<p>Before we check alignment quality, let's look at what's inside a BAM file. BAM files store alignment information in a structured format with 11 mandatory columns:</p> <pre><code># View the first few alignments in human-readable format\nsamtools view bowalign/H3K27me3_IP_rep1.sorted.bam | head -3\n</code></pre> <p>Example output (single-end data):</p> <pre><code>SRR7297994.1    0    I      15200    42    76M    *    0    0    ACGTACGT...    IIIIIIII...\nSRR7297994.2    0    II     98432    30    76M    *    0    0    TGCATGCA...    IIIHHHHH...\nSRR7297994.3   16    III    45123     0    76M    *    0    0    GATTACA...     IIIHHHGG...\n</code></pre> <p>Column Breakdown (First 5 of 11 columns):</p> Column Name Example Description 1 QNAME SRR7297994.1 Read/Query name 2 FLAG 0, 16 Bitwise FLAG (flagstat reads this!) 3 RNAME I, II, III Reference sequence name (chromosome) 4 POS 15200 Leftmost mapping position 5 MAPQ 42, 30, 0 Mapping Quality score (0-255) <p>What Each QC Tool Evaluates:</p> <p><code>samtools flagstat</code> reads Column 2 (FLAG):</p> <ul> <li>Bit 4: Read unmapped?</li> <li>Bit 256: Secondary alignment?</li> <li>Bit 1024: PCR/optical duplicate?</li> <li>Bit 2048: Supplementary alignment?</li> <li>And more... (see FLAG section below)</li> </ul> <p>[!TIP] Decode FLAGS: Use Explain SAM Flags to understand bitwise FLAG values.</p>"},{"location":"05_alignment_bowtie2/#multimapping-the-lost-gps","title":"Multimapping &amp; The \"Lost GPS\"","text":"<p>Sometimes a read is repetitive (e.g., \"ATATATAT\"). It fits in 50 different places on the genome. The aligner doesn't know which spot is correct, so it gives it a Low MAPQ Score (Mapping Quality). MAPQ filtering (<code>-q 30</code>) reads Column 5 (MAPQ):</p> <ul> <li>MAPQ = 0: \"I have NO clue where this goes. It fits in many places.\" (Multimapped)</li> <li>MAPQ &gt; 30: \"I am highly confident this read belongs EXACTLY here.\" (Unique)</li> </ul>"},{"location":"05_alignment_bowtie2/#quality-check-samtools-flagstat-samtools-stats","title":"Quality Check: <code>samtools flagstat</code> &amp; <code>samtools stats</code>","text":"<p>Did the alignment work? Let's check the score using two tools:</p> <ul> <li>flagstat: Quick alignment summary (mapped reads, pairs, etc.)</li> <li>stats: Comprehensive metrics including MAPQ distribution (for MultiQC visualization)</li> </ul> <pre><code># Create QC output directory for alignment metrics\nmkdir -p bowalign_qc\n\n# Quick summary with flagstat\nsamtools flagstat bowalign/H3K27me3_IP_rep1.sorted.bam &gt; bowalign_qc/H3K27me3_IP_rep1.flagstat.txt\n\n# Comprehensive stats (includes MAPQ distribution for MultiQC)\nsamtools stats bowalign/H3K27me3_IP_rep1.sorted.bam &gt; bowalign_qc/H3K27me3_IP_rep1.stats.txt\n</code></pre> <p>Batch processing for all samples:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nmkdir -p bowalign_qc\n\nwhile read -r sample; do\n  echo \"Running QC for: $sample\"\n\n  # Generate flagstat summary\n  samtools flagstat bowalign/${sample}.sorted.bam &gt; bowalign_qc/${sample}.flagstat.txt\n\n  # Generate comprehensive stats (for MultiQC)\n  samtools stats bowalign/${sample}.sorted.bam &gt; bowalign_qc/${sample}.stats.txt\n\ndone &lt; sample_id.txt\n\n# Generate MultiQC report with all QC results\necho \"Generating MultiQC report...\"\nmultiqc bowalign_qc/ -o bowalign_qc/ -n alignment_qc_report\necho \"MultiQC report saved: bowalign_qc/alignment_qc_report.html\"\n</code></pre> <p>This creates an interactive HTML report (<code>alignment_qc_report.html</code>) with visualizations of alignment metrics across all samples, including MAPQ distribution plots.</p> <p>What to look for:</p> <ul> <li>Mapping Rate: Ideally &gt;80-90%. If it's &lt;50%, your DNA might be contaminated (e.g., bacteria in a sample).</li> <li>Goal: High mapping percentage indicates good quality alignment.</li> <li>Warning: If mapping is low (&lt;50%), you may have the wrong organism or bad sequencing.</li> </ul> <p>The Sensitivity-Specificity Trade-off:</p> <p>Multi-mapping reads critically influence the balance between sensitivity and specificity in ChIP-seq peak detection. Excluding multi-mappers, standard practice in most peak callers, improves specificity by preventing artificial signal inflation in repetitive regions but reduces sensitivity for genuine binding events within those regions (Nakato et al., 2016). This trade-off is acceptable for transcription factors and chromatin features predominantly in unique genomic loci. However, repetitive and transposable elements (REs/TEs) constitute significant genome portions with important regulatory roles, and discarding multi-mapped reads substantially underrepresents regulatory events in these regions (Morrissey et al., 2024).</p>"},{"location":"05_alignment_bowtie2/#quick-manual-mapq-check","title":"Quick Manual MAPQ Check","text":"<p>For a quick manual inspection of MAPQ distribution (complementary to the MultiQC visualization):</p> <pre><code>samtools view bowalign/H3K27me3_IP_rep1.sorted.bam | awk '{print $5}' | sort -n | uniq -c &gt; bowalign_qc/H3K27me3_IP_rep1.mapq.txt\n</code></pre> <p>Understanding the Manual Output:</p> <ul> <li>If you see lots of 0s: Your file includes \"Lost GPS\" reads (Multimappers).</li> <li>If your scores start at 30+: Your file has Already Filtered the bad reads.</li> </ul> <p>Output format: <code>count</code> <code>MAPQ_score</code></p> <pre><code>123964  30  &lt;-- Lowest score is 30 (Good confidence)\n1928 31\n20741 32\n1477 33\n4040 34\n34434 35\n14294 36\n53329 37\n30665 38\n88528 39\n77123 40\n2960636 42  &lt;-- Highest score is 42 (Perfect confidence)\n</code></pre> <p>Verdict: This BAM file contains only uniquely mapped, high-quality reads.</p>"},{"location":"05_alignment_bowtie2/#filtering-multi-mapping-reads","title":"Filtering Multi-mapping Reads","text":"<p>For standard ChIP-seq analysis (TFs, histone marks in unique regions), filter BAM files to retain only high-quality uniquely mapped reads:</p> <pre><code># Create directory for filtered BAM files\nmkdir -p bowalign_filtered\n\n# Filter out multi-mappers (keep only MAPQ \u2265 30)\nsamtools view -b -q 30 bowalign/H3K27me3_IP_rep1.sorted.bam &gt; bowalign_filtered/H3K27me3_IP_rep1.filtered.bam\n\n# Index the filtered BAM\nsamtools index bowalign_filtered/H3K27me3_IP_rep1.filtered.bam\n</code></pre> <p>Batch processing for all samples:</p> <pre><code>#!/bin/bash\nset -euo pipefail\n\nmkdir -p bowalign_filtered\n\nwhile read -r sample; do\n  echo \"Filtering multi-mappers for: $sample\"\n  samtools view -b -q 30 bowalign/${sample}.sorted.bam &gt; bowalign_filtered/${sample}.filtered.bam\n  samtools index bowalign_filtered/${sample}.filtered.bam\ndone &lt; sample_id.txt\n</code></pre> <p>[!NOTE] The <code>-q 30</code> flag filters out reads with MAPQ &lt; 30 (removes multi-mappers and low-confidence alignments). Most downstream tools (MACS2, deepTools) can also filter by MAPQ, so this step is optional but recommended for cleaner data.</p>"},{"location":"05_alignment_bowtie2/#directory-structure-after-alignment-qc","title":"Directory Structure After Alignment QC","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 fastq_raw/\n\u251c\u2500\u2500 fastq_cleaned/\n\u251c\u2500\u2500 genome_index/\n\u251c\u2500\u2500 bowalign/                    \u2190 Aligned BAM files\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.sorted.bam\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.sorted.bam.bai\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 bowalign_log/                \u2190 Alignment statistics\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.log\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 bowalign_qc/                 \u2190 Quality control metrics\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.flagstat.txt\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.stats.txt\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.mapq.txt\n\u2502   \u251c\u2500\u2500 alignment_qc_report.html\n\u2502   \u251c\u2500\u2500 alignment_qc_report_data/\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 bowalign_filtered/           \u2190 Filtered BAM files (MAPQ \u2265 30)\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.filtered.bam\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.filtered.bam.bai\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 sample_id.txt\n</code></pre>"},{"location":"05_alignment_bowtie2/#summary","title":"Summary","text":"<ol> <li>Analogy: Alignment is placing puzzle pieces onto the reference picture.</li> <li>Action: Use <code>bowtie2</code> to align and <code>samtools sort</code> to organize.</li> <li>Result: A Sorted BAM file (the solved puzzle), ready for peak calling.</li> </ol> <p>[!NOTE] Up Next: Before peak calling, we need to remove PCR duplicates and assess library quality.</p>"},{"location":"06_duplicate_removal_qc/","title":"Handling Duplicates &amp; Quality Control","text":"<p><code>PCR-duplicates</code> <code>optical-duplicates</code> <code>Picard</code> <code>samtools</code> <code>MarkDuplicates</code> <code>deduplication</code> <code>read-groups</code> <code>MultiQC</code></p>"},{"location":"06_duplicate_removal_qc/#1-basic-concept-the-photocopier-analogy","title":"1. Basic Concept: The \"Photocopier\" Analogy","text":"<p>Imagine you are trying to read a rare, handwritten manuscript (your DNA sample). You want to digitize it, so you take photos (sequencing reads) of different pages.</p> <ul> <li>Real Signal (Enriched Regions): If many people are taking photos of the same important page because it's interesting, that's good! In ChIP-seq, this happens when a protein binds strongly to a specific DNA spot. We see many reads there because the biological signal is strong.</li> <li>Duplicates (Artifacts): Now, imagine the photocopier gets stuck and prints 100 copies of a random, unimportant page just because of a machine error. These copies don't mean that page is 100 times more important; they are just junk. In sequencing, this is called PCR duplication\u2014where the chemistry accidentally over-copies a single DNA fragment.</li> </ul> <p>Goal: We want to keep the \"popular pages\" (real biological signal) but throw away the \"accidental machine copies\" (PCR duplicates) so they don't trick us into thinking a random spot is important.</p> <p>[!NOTE] Two Tools, Same Goal: This chapter covers two methods for duplicate removal. Picard (Section 3) offers fine-grained control with read groups and optical duplicate detection\u2014ideal for complex multi-replicate studies. Samtools (Section 4) provides a simpler, single-pipeline approach\u2014sufficient for most ChIP-seq analyses. Choose the method that fits your workflow.</p>"},{"location":"06_duplicate_removal_qc/#2-understanding-the-details","title":"2. Understanding the Details","text":"<p>For those who want to understand the \"under the hood\" mechanics, here is what are different types of duplicates and  the Read Groups .</p>"},{"location":"06_duplicate_removal_qc/#pcr-vs-optical-duplicates","title":"PCR vs. Optical Duplicates","text":"Type Origin Typical Cause Implication PCR Duplicates Library Prep Over-cycling (amplifying DNA too much) Shows low library complexity (not enough unique DNA to start with). Optical Duplicates Sequencer Camera errors reads the same cluster as two Technical glitch on the flow cell."},{"location":"06_duplicate_removal_qc/#the-role-of-read-groups-rg","title":"The Role of Read Groups (RG)","text":"<p>A Read Group is a tag that tells the software \"this read came from Sample A, Run 1.\"</p> <ul> <li>Why is it vital? If you merge two different samples (e.g., Replicate 1 and Replicate 2), you might have two different reads that coincidentally map to the same spot.</li> <li>Without Read Groups, Picard acts blindly: \"These look identical! Delete one!\" -&gt; Data Loss.</li> <li>With Read Groups, Picard sees: \"Oh, one is from Replicate 1 and one is from Replicate 2. They are different samples. Keep both!\"</li> </ul> <p>*Full hierarchy in RGing</p> <pre><code>RGSM  \u2192 biological sample (Control H3k9ac)\n  \u2514\u2500\u2500 RGLB \u2192 library prep (usually lib1 however if Different library preps (even from same sample) RGLB=lib1 RGLB=lib2 )\n        \u2514\u2500\u2500 RGPU \u2192 flowcell + lane (from header of Fastq file )\n              \u2514\u2500\u2500 RGID \u2192 unique ID tying it all together (replicates: H3K27me3_IP_rep1, H3K27me3_IP_rep2)\n</code></pre>"},{"location":"06_duplicate_removal_qc/#3-marking-removing-duplicates-why-picard-is-unique","title":"3. Marking &amp; Removing Duplicates: Why Picard is Unique","text":"<p>Picard stands out among duplicate-marking tools because it:</p> <ul> <li>Distinguishes optical vs. PCR duplicates during QC reporting.  </li> <li>Leverages read group (RG) identifiers to avoid over-collapsing reads when combining multiple replicates or lanes.  </li> <li>Provides metrics for each library or sample, enabling fine-grained quality control.</li> </ul> <p>Picard\u2019s RG-aware logic ensures duplicates are flagged within, but not across, biological replicates or lanes \u2014 preventing false duplicate marking when BAMs are merged.</p>"},{"location":"06_duplicate_removal_qc/#31-adding-rgs-to-each-bam-file","title":"3.1 Adding RGs to each Bam file","text":"<p>Minimal augmented RG setup (merge BAM replicates)</p> <p>This read-group configuration is designed for the simplest defensible case: merging biological or technical ChIP-seq replicates and proceeding directly to peak calling.</p> <p>Input files needed:</p> <ul> <li>Filtered BAM file: <code>bowalign_filtered/H3K27me3_IP_rep1.filtered.bam</code> (from section 05)</li> </ul> <pre><code>mkdir -p picard_rg_bam\n\npicard AddOrReplaceReadGroups \\\n  I=bowalign_filtered/H3K27me3_IP_rep1.filtered.bam \\\n  O=picard_rg_bam/H3K27me3_IP_rep1.RG.bam \\\n  RGID=H3K27me3_IP_rep1 \\\n  RGSM=H3K9ac\n</code></pre> <p>What this does:</p> <ul> <li>I= specifies the input BAM file from the alignment step</li> <li>O= specifies the output BAM file with read-group tags added</li> <li>RGID= sets a unique Read Group ID (one per replicate)</li> <li>RGSM= sets the biological sample name (used for grouping replicates)</li> </ul> <p>Minimal augmented RG setup (optical duplicates enabled)</p> <p>This configuration extends the previous one by adding the minimum required metadata to make optical duplicate detection meaningful. The addition of RGPU, encoding the flowcell and lane, defines the physical neighborhood in which optical duplicates can occur.</p> <pre><code>picard AddOrReplaceReadGroups \\\n  I=bowalign_filtered/H3K27me3_IP_rep1.filtered.bam \\     # Input: MAPQ-filtered BAM from section 05\n  O=picard_rg_bam/H3K27me3_IP_rep1.RG.bam \\           # Output with RG tags\n  RGID=H3K27me3_IP_rep1 \\                      # Read Group ID\n  RGSM=H3K9ac \\                          # Biological sample\n  RGPL=ILLUMINA \\                        # REQUIRED for optical duplicate logic\n  RGPU=CA0TUACXX.1                       # REQUIRED: flowcell.lane (from FASTQ header)\n</code></pre> <p>More from GATK: Read Groups Picard markduplicates</p>"},{"location":"06_duplicate_removal_qc/#step-32-mark-duplicates-be-careful","title":"Step 3.2: Mark Duplicates (Be Careful!)","text":"<p>First, we will just mark the duplicates but keep them in the file. This is like highlighting the duplicate pages in yellow but not throwing them in the trash yet. This is important for Quality Control (QC) to see how bad the duplication problem is.</p> <p>Input files needed:</p> <ul> <li>Filtered BAM file with read groups: <code>picard_rg_bam/H3K27me3_IP_rep1.RG.bam</code></li> </ul> <pre><code># ----- 3.3 Mark duplicates (keep all reads, just mark) -----\n\nmkdir -p picard_markdup picard_markdup_metrics\n\n# Run Picard MarkDuplicates\npicard MarkDuplicates \\\n  I=picard_rg_bam/H3K27me3_IP_rep1.RG.bam \\\n  O=picard_markdup/H3K27me3_IP_rep1.marked.bam \\\n  M=picard_markdup_metrics/H3K27me3_IP_rep1.metrics.txt \\\n  REMOVE_DUPLICATES=false\n\n# Index the new file\nsamtools index picard_markdup/H3K27me3_IP_rep1.marked.bam\n</code></pre> <p>What this does:</p> <ul> <li>I= specifies input BAM file with read groups</li> <li>O= specifies output BAM file with duplicates marked (not removed)</li> <li>M= creates metrics file reporting duplicate statistics</li> <li>REMOVE_DUPLICATES=false marks duplicates but keeps all reads in the file</li> <li>samtools index creates index for marked BAM file</li> </ul> <p>[!IMPORTANT] Why keep marked files? The Picard metrics file (<code>.metrics.txt</code>) contains duplicate rates that MultiQC can aggregate into summary reports. However, for downstream analysis (peak calling, BigWig generation), always use the deduplicated BAMs to prevent PCR artifacts from inflating your signal.</p> <p>Note: While MACS can handle duplicates internally via <code>--keep-dup</code> options, using pre-deduplicated BAMs is the recommended practice\u2014it gives you explicit control and avoids relying on MACS's position-based duplicate detection, which differs from Picard/samtools fragment-level detection. [GitHub #33] [Biostars]</p> <p>Aggregate metrics with MultiQC:</p> <pre><code># Run MultiQC on Picard metrics folder\nmultiqc picard_dedup_metrics/ -o multiqc_report/\n</code></pre> <p>This generates an interactive HTML report showing duplicate rates across all samples.</p>"},{"location":"06_duplicate_removal_qc/#step-33-remove-duplicates-clean-up","title":"Step 3.3: Remove Duplicates (Clean Up)","text":"<p>Now that we've checked the quality, we create a \"clean\" version of our data for analysis. We remove the marked duplicates so they don't interfere with peak calling.</p> <pre><code># ----- 3.4 Create a duplicate-removed BAM by filtering marked BAM -----\n\nmkdir -p picard_dedup_bam picard_dedup_metrics\n\n# Run Picard to REMOVE duplicates\npicard MarkDuplicates \\\n  I=picard_rg_bam/H3K27me3_IP_rep1.RG.bam \\\n  O=picard_dedup_bam/H3K27me3_IP_rep1.dedup.bam \\\n  M=picard_dedup_metrics/H3K27me3_IP_rep1.metrics.txt \\\n  REMOVE_DUPLICATES=true\n\n# Index the new file\nsamtools index picard_dedup_bam/H3K27me3_IP_rep1.dedup.bam\n</code></pre> <ul> <li><code>REMOVE_DUPLICATES=true</code>: This time, we actually delete the highlighted duplicates.</li> </ul>"},{"location":"06_duplicate_removal_qc/#after-picard-deduplication","title":"After Picard Deduplication","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 fastq_raw/\n\u251c\u2500\u2500 fastq_cleaned/\n\u251c\u2500\u2500 genome_index/\n\u251c\u2500\u2500 bowalign/                    \u2190 Aligned BAMs\n\u251c\u2500\u2500 bowalign_filtered/           \u2190 Filtered BAMs\n\u251c\u2500\u2500 picard_rg_bam/               \u2190 BAMs with Read Groups\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.RG.bam\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.RG.bam.bai\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 picard_dedup_bam/            \u2190 Final Deduplicated BAMs\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.dedup.bam\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.dedup.bam.bai\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 picard_metrics/              \u2190 Duplication Reports\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.metrics.txt\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 sample_id.txt\n</code></pre>"},{"location":"06_duplicate_removal_qc/#4-samtools-simple-alternative","title":"4. Samtools (Simple Alternative)","text":"<p>Samtools provides a lightweight and reliable way to handle duplicates without the complexity of read groups. Choose this option if you want a straightforward workflow.</p>"},{"location":"06_duplicate_removal_qc/#step-41-prepare-bam-for-duplicate-detection","title":"Step 4.1: Prepare BAM for Duplicate Detection","text":"<pre><code># Paired-end mates are placed next to each other. Groups reads by read name\nsamtools collate -o temp/H3K27me3_IP_rep1.collate.bam bowalign_filtered/H3K27me3_IP_rep1.filtered.bam\n\n# Synchronize mate flags and add mate-related tags\nsamtools fixmate -m temp/H3K27me3_IP_rep1.collate.bam temp/H3K27me3_IP_rep1.fixmate.bam\n\n# Coordinate sort for duplicate marking\nsamtools sort -o temp/H3K27me3_IP_rep1.positionsort.bam temp/H3K27me3_IP_rep1.fixmate.bam\n</code></pre>"},{"location":"06_duplicate_removal_qc/#step-42-mark-duplicates-keep-for-qc","title":"Step 4.2: Mark Duplicates (Keep for QC)","text":"<pre><code># Mark duplicates but KEEP them in the output\nsamtools markdup temp/H3K27me3_IP_rep1.positionsort.bam samtools_markdup/H3K27me3_IP_rep1.marked.bam\n\n# Index the file\nsamtools index samtools_markdup/H3K27me3_IP_rep1.marked.bam\n</code></pre>"},{"location":"06_duplicate_removal_qc/#step-43-remove-duplicates-clean-for-analysis","title":"Step 4.3: Remove Duplicates (Clean for Analysis)","text":"<pre><code># Remove duplicates with -r flag\nsamtools markdup -r temp/H3K27me3_IP_rep1.positionsort.bam samtools_dedup_bam/H3K27me3_IP_rep1.dedup.bam\n\n# Index the file\nsamtools index samtools_dedup_bam/H3K27me3_IP_rep1.dedup.bam\n</code></pre> <p>This samtools-based workflow is simpler than Picard and avoids the need for read-group metadata, while still providing accurate duplicate detection for paired-end data.</p>"},{"location":"06_duplicate_removal_qc/#step-44-automation-loop-all-samples","title":"Step 4.4: Automation Loop (All Samples)","text":"<pre><code>#!/bin/bash\nset -euo pipefail\n\nmkdir -p samtools_dedup_bam\n\nwhile read -r sample; do\n  echo \"Processing $sample...\"\n\n  # All steps piped together - no temp files needed!\n  samtools collate -u -O \"bowalign_filtered/${sample}.filtered.bam\" | \\\n    samtools fixmate -m -u - - | \\\n    samtools sort -u - | \\\n    samtools markdup -r - \"samtools_dedup_bam/${sample}.dedup.bam\"\n\n  # Index the final output\n  samtools index \"samtools_dedup_bam/${sample}.dedup.bam\"\n\n  echo \"Finished $sample\"\ndone &lt; sample_id.txt\n</code></pre> <p>Why use pipes?</p> <pre><code>collate \u2192 fixmate \u2192 sort \u2192 markdup\n  \u2193         \u2193        \u2193       \u2193\n pipe     pipe     pipe    file\n</code></pre> <ul> <li><code>-u</code> flag: Outputs uncompressed BAM for faster streaming between commands</li> <li><code>-</code> symbol: Represents stdin/stdout, allowing data to flow through the pipeline</li> <li>No temp files: Everything processes in memory, saving disk space and I/O time</li> <li>Faster: No waiting for disk writes between each step</li> </ul> <p>More samtools</p>"},{"location":"06_duplicate_removal_qc/#after-samtools-deduplication","title":"After Samtools Deduplication","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 bowalign_filtered/           \u2190 Input: MAPQ-filtered BAM files (from section 05)\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.filtered.bam\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 samtools_markdup/            \u2190 Duplicates marked (not removed)\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.marked.bam\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 samtools_dedup_bam/          \u2190 Duplicates removed\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.dedup.bam\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.dedup.bam.bai\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 sample_id.txt\n</code></pre>"},{"location":"06_duplicate_removal_qc/#summary","title":"Summary","text":"<ol> <li>Understand: PCR duplicates inflate signal artificially; we mark/remove them.</li> <li>Action: Use Picard (with read groups) or samtools to handle duplicates.</li> <li>Result: Clean, deduplicated BAM files ready for peak calling.</li> </ol> <p>[!NOTE] Up Next: We'll assess library complexity to understand how deeply our libraries were sequenced.</p>"},{"location":"07_library_complexity/","title":"Library Complexity (The \"Street Photographer\")","text":"<p><code>library-complexity</code> <code>NRF</code> <code>PBC</code> <code>PCR-duplicates</code> <code>bedtools</code> <code>unique-reads</code> <code>QC-metrics</code></p>"},{"location":"07_library_complexity/#level-1-basic-concept-the-photographer","title":"Level 1: Basic Concept (The Photographer)","text":"<p>Imagine you are a Street Photographer in a busy city. Your goal is to capture the diversity of the population.</p> <ul> <li>High Complexity Library (Good): You take 100 photos, and every photo shows a different person. You have captured the true variety of the city.</li> <li>Low Complexity Library (Bad): You take 100 photos, but it's just the same person 100 times. You wasted your film (sequencing reads) on duplicates.</li> </ul> <p>In ChIP-seq, if we keep sequencing the exact same DNA fragment over and over (PCR duplicates), we aren't learning anything new. We want a \"Complex\" library with many unique fragments.</p>"},{"location":"07_library_complexity/#level-2-execution-the-calculator","title":"Level 2: Execution (The Calculator)","text":"<p>We calculate complexity using metrics called NRF and PBC. This calculation is a bit complex, so we use a script that combines <code>bedtools</code>, <code>sort</code>, and <code>awk</code>.</p> <p>Input files needed:</p> <pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 picard_dedup_bam/\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.dedup.bam\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 QC_results/\n\u2502   \u251c\u2500\u2500 H3K27me3_IP_rep1.pbc.txt\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 sample_id.txt\n</code></pre> <p>Run this command block for one sample:</p> <pre><code>mkdir -p QC_results\n\n# 1. Create a \"5-prime\" BED file\n# (Convert BAM to simple coordinates, keeping only the start position of each read)\nbedtools bamtobed -i picard_dedup_bam/H3K27me3_IP_rep1.dedup.bam \\\n  | awk 'BEGIN{OFS=\"\\t\"} ($6==\"+\"){print $1,$2,$2+1} ($6==\"-\"){print $1,$3-1,$3}' \\\n  | sort -k1,1 -k2,2n \\\n  &gt; QC_results/Sample1.read5.bed\n\n# 2. Compute NRF, PBC1, PBC2\n# (Count how many times each position appears)\nuniq -c QC_results/Sample1.read5.bed \\\n  | awk '{c=$1; total+=c; uniq++; if(c==1) single++; if(c==2) double++;} \\\n    END{ if(total==0){print \"NRF=NA\\tPBC1=NA\\tPBC2=NA\"; exit} \\\n    NRF=uniq/total; \\\n    PBC1=single/uniq; \\\n    PBC2=(double? single/double:\"Inf\"); \\\n    printf(\"NRF=%.3f\\tPBC1=%.3f\\tPBC2=%s\\n\", NRF, PBC1, PBC2); }' \\\n  &gt; QC_results/Sample1.pbc.txt\n</code></pre> <p>Check the result:</p> <pre><code>cat QC_results/Sample1.pbc.txt\n</code></pre> <pre><code>NRF=0.997 PBC1=0.997 PBC2=360.061\n</code></pre>"},{"location":"07_library_complexity/#understanding-the-metrics","title":"Understanding the Metrics","text":"<ul> <li>NRF (Non-Redundant Fraction): <code>Unique Reads / Total Reads</code>. (Ideal: &gt; 0.8)</li> <li>PBC1 (PCR Bottleneck Coefficient 1): <code>Genomic positions with 1 read / Genomic positions with \u22651 read</code>. (Ideal: &gt; 0.8)</li> <li>PBC2 (PCR Bottleneck Coefficient 2): <code>Positions with 1 read / Positions with 2 reads</code>. (Ideal: &gt; 3.0)</li> </ul>"},{"location":"07_library_complexity/#encode-guidelines","title":"ENCODE Guidelines","text":"<p>How good is your library? Use this chart from ENCODE to grade your data.</p> <p></p> <p>Source: ENCODE Data Standards</p>"},{"location":"07_library_complexity/#before-vs-after-deduplication","title":"Before vs. After Deduplication","text":"<p>Crucial Concept: Raw data often looks \"Low Complexity\" just because of PCR duplicates. This is misleading. Once you remove the duplicates, the remaining data reveals the true quality of your library.</p> <p>Example Comparison:</p> Stage NRF PBC1 PBC2 Interpretation Before Removal 0.668 0.695 3.3 Appears \"Moderate/Low\" quality due to duplicates. After Removal 0.952 0.949 18.6 Use these values! True library is High Quality. <p>Lesson: Don't panic if your raw NRF is low. Remove duplicates first, then check again.</p>"},{"location":"07_library_complexity/#summary","title":"Summary","text":"<ol> <li>Goal: Ensure we have many unique DNA fragments (High Complexity).</li> <li>Action: Run the NRF/PBC calculation script.</li> <li>Result: Compare your numbers against the ENCODE chart to validate your experiment.</li> </ol> <p>[!NOTE] Up Next: We'll dive deeper into BAM quality metrics to assess alignment quality and fragment sizes.</p>"},{"location":"07_library_complexity/#pipeline-summary-pre-processing-workflow-complete","title":"Pipeline Summary: Pre-processing Workflow Complete","text":"<p>Congratulations! You have completed the core ChIP-seq pre-processing workflow from raw sequencing reads to analysis-ready BAM files.</p> <p>Pre-processing Pipeline:</p> <ul> <li>FASTQ Acquisition: Downloaded from GEO/SRA (C. elegans H3K27me3 ChIP-seq, single-end reads)</li> <li>Sample Manifest: Created sample ID list for batch processing</li> <li>Quality Control: Read quality assessment and adapter trimming (fastp)</li> <li>Genome Alignment: Mapped reads to reference assembly (Bowtie2, single-end mode)</li> <li>Duplicate Removal: PCR duplicate identification and removal (Picard MarkDuplicates)</li> <li>Library Complexity: QC assessment with NRF, PBC1, PBC2 metrics</li> </ul> <p>Analysis-ready outputs:</p> <ul> <li>Deduplicated, coordinate-sorted BAM files with index (.bai)</li> <li>Per-sample QC metrics (alignment rate, duplication rate, complexity)</li> <li>Quality-filtered reads ready for peak calling</li> </ul>"},{"location":"07_library_complexity/#transition-to-encode-bam-files","title":"Transition to ENCODE BAM Files","text":"<p>[!IMPORTANT] For downstream analysis, we will use pre-processed BAM files from ENCODE instead of the files we generated during pre-processing.</p> <p>Why?</p> <ul> <li>ENCODE provides high-quality, standardized ChIP-seq data</li> <li>Files are already aligned, deduplicated, and quality-controlled</li> <li>This allows us to focus on downstream analysis (peak calling, visualization, annotation)</li> </ul> <p>What this means:</p> <ul> <li>The pre-processing workflow taught you complete data preparation from raw reads to analysis-ready BAM</li> <li>Downstream analysis will use ENCODE BAM files for demonstration</li> <li>You can apply both approaches: process your own data OR use public ENCODE data</li> </ul> <p>The skills you learned in the pre-processing workflow are valuable for processing your own ChIP-seq data. For the remaining tutorials, we'll demonstrate downstream analysis using ENCODE's curated datasets.</p> <p>[!TIP] Challenge yourself! Before moving to downstream analysis, consider applying the downstream analysis steps (peak calling, visualization, annotation) to your C. elegans H3K27me3 data from the pre-processing workflow. This hands-on practice will solidify your understanding and give you complete end-to-end ChIP-seq analysis experience. You can then compare your results with the ENCODE workflow!</p>"},{"location":"08_bam_quality_metrics/","title":"Experiment Design &amp; BAM Quality Control","text":"<p><code>ENCODE</code> <code>BAM-files</code> <code>samtools</code> <code>flagstat</code> <code>MAPQ</code> <code>quality-control</code> <code>alignment-QC</code> <code>deepTools</code> <code>single-end</code></p>"},{"location":"08_bam_quality_metrics/#1-basic-concept-the-experiment-the-file","title":"1. Basic Concept (The Experiment &amp; The File)","text":""},{"location":"08_bam_quality_metrics/#11-the-experiment-story","title":"1.1 The Experiment Story","text":"<p>This tutorial uses real data from BLaER1 cells (human immune cells).</p> <ul> <li>Treatment: Cells were treated for 18 hours with Estradiol, Interleukin-3, and CSF1 to activate specific genes.</li> <li>The Targets:<ol> <li>CEBPA: A Transcription Factor (The \"Driver\" that turns on genes).</li> <li>H3K27me3: A Histone Mark for Closed/Repressed DNA (The \"Stop Sign\").</li> <li>H3K9ac: A Histone Mark for Open/Active DNA (The \"Go Sign\").</li> <li>Input: Random background DNA (The \"Noise\" control).</li> </ol> </li> </ul>"},{"location":"08_bam_quality_metrics/#12-the-zip-file-analogy-bam-vs-sam","title":"1.2 The \"Zip File\" Analogy (BAM vs SAM)","text":"<ul> <li>SAM File (Sequence Alignment Map): This is a huge, readable text file. It's like a 1000-page printed manuscript.</li> <li>BAM File (Binary Alignment Map): This is the Compressed Zip File version. It contains the exact same info but is smaller and faster for the computer to read.</li> <li>Rule: We always work with BAM files to save space and time.</li> </ul> <p>Data Availability:</p> <ul> <li>ENCODE Cart</li> </ul>"},{"location":"08_bam_quality_metrics/#2-data-used-in-the-tutorial","title":"2. Data used in the tutorial","text":""},{"location":"08_bam_quality_metrics/#21-sample-table","title":"2.1 Sample Table","text":"<p>Here are the files we are analyzing. In real life, you should make a table like this to track your work.</p> Biosample Accession ChIP Type Target Custom BAM Filename ENCFF327JFG TF ChIP-seq CEBPA ceb_ENCFF327JFG.bam ENCFF744SVA TF ChIP-seq CEBPA ceb_ENCFF744SVA.bam ENCFF164ALR Histone ChIP-seq H3K27me3 H3K27me3_ENCFF164ALR.bam ENCFF532DQH Histone ChIP-seq H3K27me3 H3K27me3_ENCFF532DQH.bam ENCFF193NPE Histone ChIP-seq H3K9ac H3K9ac_ENCFF193NPE.bam ENCFF534IPX Histone ChIP-seq H3K9ac H3K9ac_ENCFF534IPX.bam ENCFF110SOB Control ChIP-seq Input Input_ENCFF110SOB.bam ENCFF919XCV Control ChIP-seq Input Input_ENCFF919XCV.bam"},{"location":"08_bam_quality_metrics/#22-simplest-and-easiet-way-to-donwload-all-the-bam-files-in-the-working-folder","title":"2.2 Simplest and easiet way to donwload all the bam files in the working folder","text":"<pre><code>#!/bin/bash\nset -euo pipefail\n\ncat &lt;&lt;EOF | xargs -n 2 -P 4 wget -c -O\nceb_ENCFF327JFG.bam        https://www.encodeproject.org/files/ENCFF327JFG/@@download/ENCFF327JFG.bam\nceb_ENCFF744SVA.bam        https://www.encodeproject.org/files/ENCFF744SVA/@@download/ENCFF744SVA.bam\nH3K27me3_ENCFF164ALR.bam   https://www.encodeproject.org/files/ENCFF164ALR/@@download/ENCFF164ALR.bam\nH3K27me3_ENCFF532DQH.bam   https://www.encodeproject.org/files/ENCFF532DQH/@@download/ENCFF532DQH.bam\nH3K9ac_ENCFF193NPE.bam     https://www.encodeproject.org/files/ENCFF193NPE/@@download/ENCFF193NPE.bam\nH3K9ac_ENCFF534IPX.bam     https://www.encodeproject.org/files/ENCFF534IPX/@@download/ENCFF534IPX.bam\nInput_ENCFF110SOB.bam      https://www.encodeproject.org/files/ENCFF110SOB/@@download/ENCFF110SOB.bam\nInput_ENCFF919XCV.bam      https://www.encodeproject.org/files/ENCFF919XCV/@@download/ENCFF919XCV.bam\nEOF\n</code></pre>"},{"location":"08_bam_quality_metrics/#3-basic-quality-checks","title":"3. Basic Quality Checks","text":"<p>Before processing, we verify the BAM files are healthy. For detailed explanations of these metrics, see Section 05: Alignment QC.</p> <p>3.1. Create a smaller test file (Optional) Working with full genomes takes time. For testing, we can extract just chromosome 11 and 12:</p> <pre><code>samtools view -b -h ceb_ENCFF327JFG.bam chr11 chr12 | samtools sort -o ceb_ENCFF327JFG.chr11_12.bam\n</code></pre> <p>3.2. Get Alignment Stats</p> <p>For detailed explanation of <code>flagstat</code> output, see Understanding BAM File Structure.</p> <pre><code># Quick summary\nsamtools flagstat ceb_ENCFF327JFG.bam &gt; ceb_ENCFF327JFG.flagstat.txt\ncat ceb_ENCFF327JFG.flagstat.txt\n</code></pre> <p>Output:</p> <pre><code>2565563 + 0 in total (QC-passed reads + QC-failed reads)\n2565563 + 0 primary\n0 + 0 secondary\n0 + 0 supplementary\n0 + 0 duplicates\n0 + 0 primary duplicates\n2565563 + 0 mapped (100.00% : N/A)\n2565563 + 0 primary mapped (100.00% : N/A)\n0 + 0 paired in sequencing\n0 + 0 read1\n0 + 0 read2\n0 + 0 properly paired (N/A : N/A)\n0 + 0 with itself and mate mapped\n0 + 0 singletons (N/A : N/A)\n0 + 0 with mate mapped to a different chr\n0 + 0 with mate mapped to a different chr (mapQ&gt;=5)\n</code></pre> <p>Verdict: 100% mapping rate - High-quality alignment, single-end data, no duplicates</p> <p>3.3. Check MAPQ Distribution</p> <p>For detailed explanation of MAPQ scores and multimapping, see Multimapping &amp; The \"Lost GPS\".</p> <pre><code>samtools view ceb_ENCFF327JFG.bam | awk '{print $5}' | sort -n | uniq -c\n</code></pre> <p>Output:</p> <pre><code>123964  30  \u2190 Lowest score is 30 (Good confidence)\n1928 31\n20741 32\n1477 33\n4040 34\n34434 35\n14294 36\n53329 37\n30665 38\n88528 39\n77123 40\n2960636 42  \u2190 Highest score is 42 (Perfect confidence)\n</code></pre> <p>Verdict: MAPQ \u2265 30 - File contains only uniquely mapped, high-quality reads</p>"},{"location":"08_bam_quality_metrics/#directory-structure-after-bam-qc","title":"Directory Structure After BAM QC","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 encode_bam/                  \u2190 ENCODE BAM files\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG.bam\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE.bam\n\u2502   \u2514\u2500\u2500 ...                      (8 BAM files total)\n\u251c\u2500\u2500 encode_bam_qc/               \u2190 QC metrics for ENCODE BAMs\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG.flagstat.txt\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG.mapq.txt\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE.flagstat.txt\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE.mapq.txt\n\u2502   \u2514\u2500\u2500 ...                      (16 QC files total)\n\u2514\u2500\u2500 sample_id.txt\n</code></pre>"},{"location":"08_bam_quality_metrics/#summary","title":"Summary","text":"<ol> <li>Context: We are analyzing active/repressed marks in BLaER1 cells.</li> <li>Files: BAMs are compressed alignment maps.</li> <li>QC: We use <code>samtools flagstat</code> and check MAPQ scores to ensure we aren't analyzing \"lost\" multimapping reads.</li> </ol> <p>[!NOTE] Up Next: We'll perform cross-correlation analysis to estimate fragment length and assess signal quality.</p>"},{"location":"09_strand_cross_correlation/","title":"Strand Cross-Correlation (The Echo)","text":"<p><code>cross-correlation</code> <code>PhantomPeakQualTools</code> <code>fragment-length</code> <code>NSC</code> <code>RSC</code> <code>phantom-peak</code> <code>ChIP-seq</code> <code>quality-control</code> <code>run_spp.R</code> <code>ENCODE</code></p>"},{"location":"09_strand_cross_correlation/#1-basic-concept-the-echo","title":"1: Basic Concept (The Echo)","text":""},{"location":"09_strand_cross_correlation/#why-do-we-see-two-peaks","title":"Why do we see two peaks?","text":"<p>When you do ChIP-seq, the DNA fragments are 3D objects, about 200bp long, with the protein in the middle. However, the sequencer only reads the Ends of these fragments (5' ends).</p> <ul> <li>Forward Strand Reads: Read from the left end (Start of fragment).</li> <li>Reverse Strand Reads: Read from the right end (End of fragment).</li> </ul> <p>This creates two piles of reads separated by the fragment length, like two mountains with a valley in between.</p>"},{"location":"09_strand_cross_correlation/#the-echo-analogy","title":"The Echo Analogy","text":"<p>Imagine you shout \"HELLO\" (Forward Reads). A split second later, you hear the echo \"HELLO\" (Reverse Reads).</p> <ul> <li>Cross-Correlation is measuring exactly how long that delay is.</li> <li>We slide the Forward reads towards the Reverse reads. When they overlap perfectly, the \"volume\" is loudest (Max Correlation).</li> <li>The distance we slid them telling us the True Fragment Length.</li> </ul> <p></p> <p>(Source:Genome-wide analysis of transcription factor binding sites based on ChIP-Seq data</p>"},{"location":"09_strand_cross_correlation/#2-phantompeakqualtools","title":"2: PhantomPeakQualTools","text":"<p>We use a tool called <code>run_spp.R</code> (part of PhantomPeakQualTools ) to calculate this. It finds the \"Best Match\" distance.</p>"},{"location":"09_strand_cross_correlation/#the-command","title":"The Command","text":"<pre><code># Run PhantomPeakQualTools\nRscript /opt/anaconda3/envs/chip/bin/run_spp.R \\\n      -c=sample.bam \\\n      -savp=Sample1_spp.qc.pdf \\\n      -out=Sample1_spp.qc.txt\n</code></pre> <p>Explanation:</p> <ul> <li><code>-c</code>: Input BAM file.</li> <li><code>-savp</code>: Saves the diagnostic PDF plot (The \"Echo\" graph).</li> <li><code>-out</code>: Output file containing the score numbers (NSC and RSC).</li> </ul>"},{"location":"09_strand_cross_correlation/#level-3-analysis-signal-vs-noise","title":"Level 3: Analysis (Signal vs Noise)","text":"<p>The output plot (<code>Sample1_spp.qc.pdf</code>) usually shows TWO peaks. This is where quality control happens.</p>"},{"location":"09_strand_cross_correlation/#31-the-peaks","title":"3.1 The Peaks","text":"<ol> <li> <p>The Real Peak (Red Line):</p> <ul> <li>What is it? The \u201cEcho\u201d. The point where Forward and Reverse reads overlap because they bind the same protein.</li> <li>Location: Usually around 150-250 bp (your fragment size).</li> <li>Meaning: Represents Biological Signal.</li> </ul> </li> <li> <p>The Phantom Peak (Blue Line):</p> <ul> <li>What is it? \u201cMicrophone Feedback\u201d. It occurs at the Read Length (e.g., 50bp or 100bp).</li> <li>Why? It's caused by mapping artifacts and \"sticky\" sequences. It happens in every experiment, even bad ones.</li> <li>Meaning: Represents Background Noise.</li> </ul> </li> </ol> <p><code>Sample1_spp.qc.txt</code> provides numeric QC metrics in colunmns from 1-11</p> <pre><code>H3K9ac_ENCFF193NPE.chr11_12.bam   #1  BAM file name (input to SPP QC)\n3411159                          #2  Number of reads used\n220                              #3  Estimated fragment length (bp)\n0.545418                         #4  Cross-correlation at fragment length\n55                               #5  Phantom peak shift (bp)\n0.501850                         #6  Cross-correlation at phantom peak\n1500                             #7  Maximum strand shift tested (bp)\n0.373681                         #8  Minimum cross-correlation (background)\n1.459581                         #9  NSC \u2013 Normalized Strand Cross-correlation\n1.339926                         #10 RSC \u2013 Relative Strand Cross-correlation\n1                               #11 SPP quality tag (1 = good)\n</code></pre> <p></p>"},{"location":"09_strand_cross_correlation/#32-the-metrics-nsc-rsc","title":"3.2 The Metrics (NSC &amp; RSC)","text":"<p>We compare the Height of the Real Peak (Signal) to the Phantom Peak (Noise).</p> <p>Key Metrics Table:</p> Metric Full Name Meaning Good Threshold NSC Normalized Strand Cross-correlation Signal-to-Noise Ratio. How much higher is the Real Peak (COL4) than the flat background (COL8)? (COL4 / COL8) &gt; 1.05 RSC Relative Strand Cross-correlation Signal vs Phantom. Is the Real Peak (COL4) clearly stronger than the Phantom Peak (COL6)? ((COL4 \u2013 COL8) / (COL6 \u2013 COL8)) &gt; 0.8"},{"location":"09_strand_cross_correlation/#33-interpreting-the-data-example-analysis","title":"3.3 Interpreting the Data (Example Analysis)","text":"<ul> <li>As shown in the plot, expectedly, the two input samples show the typical profile of unenriched DNA, with very low signal-to-noise. Their NSC values sit almost exactly at background (1.003 and 1.005), and their RSC values are only 0.62 and 0.64, which is far below what any real ChIP signal produces (NSC  &gt; 1.05 &amp; RSC &gt; 0.8)</li> </ul> <p>Also , <code>corelation values</code> are worth to look at :</p> <ul> <li>Inputs (Control):</li> <li>The numerically high correlation values (0.5509 and 0.5474) are driven by the dominant phantom peak, not real enrichment.</li> <li>H3K9ac (Active Mark):</li> <li>Correlation is High (0.5454 and 0.4112).</li> <li>Interpretation: Strong signal. Acetylation marks usually give huge peaks, reflecting the broad and high-coverage nature of these marks.</li> <li>H3K27me3 (Repressive Mark):</li> <li>Correlation is Medium (0.3708 and 0.3572).</li> <li>Interpretation: Expected. Repressive marks are broad and diffuse, so the \"Echo\" is quieter, fitting a repressive mark that produces wide but moderate enrichment.</li> <li>CEBPA (Transcription Factor):</li> <li>Correlation is Lower (0.2876 and 0.1979).</li> <li>Interpretation: TF peaks are sharp but rare (small % of genome). Total signal is lower, but the peaks are distinct. This is expected because TF peaks are sharp and occupy a small fraction of the genome, so their genome-wide cross-correlation values are naturally smaller.</li> </ul>"},{"location":"09_strand_cross_correlation/#directory-structure-after-cross-correlation-qc","title":"Directory Structure After Cross-Correlation QC","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 encode_bam/                  \u2190 ENCODE BAM files\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG.bam\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE.bam\n\u2502   \u2514\u2500\u2500 ...                      (8 BAM files total)\n\u251c\u2500\u2500 encode_bam_qc/               \u2190 QC metrics from section 08\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG.flagstat.txt\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG.mapq.txt\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE.flagstat.txt\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE.mapq.txt\n\u2502   \u2514\u2500\u2500 ...                      (16 QC files total)\n\u251c\u2500\u2500 spp_qc/                      \u2190 PhantomPeakQualTools outputs\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG_spp.qc.pdf\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG_spp.qc.txt\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE_spp.qc.pdf\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE_spp.qc.txt\n\u2502   \u2514\u2500\u2500 ...                      (16 SPP files total)\n\u2514\u2500\u2500 sample_id.txt\n</code></pre>"},{"location":"09_strand_cross_correlation/#summary","title":"Summary","text":"<ol> <li>Cross-Correlation shifts reads to find the fragment length (The Echo).</li> <li>Phantom Peak is a background artifact at read length (Microphone Feedback).</li> <li>RSC &gt; 0.8 means your Signal (Real Peak) is louder than your Noise (Phantom Peak).</li> </ol> <p>[!NOTE] Up Next: We'll perform comprehensive QC using deepTools to validate enrichment and sample consistency before peak calling.</p>"},{"location":"10_bam_summary_fingerprint/","title":"Advanced QC with deepTools (The \"Health Checkup\")","text":"<p><code>deepTools</code> <code>plotFingerprint</code> <code>plotCoverage</code> <code>multiBamSummary</code> <code>correlation</code> <code>PCA</code> <code>ChIP-seq</code> <code>quality-control</code> <code>enrichment</code> <code>BAM-QC</code></p>"},{"location":"10_bam_summary_fingerprint/#1-basic-concept-the-health-check","title":"1. Basic Concept (The Health Check)","text":"<p>Before we call peaks, we must perform a Health Checkup on our data.</p> <ul> <li>The Census (Fingerprint): Are the reads spread out evenly (Socialist/Input) or concentrated in specific spots (Capitalist/ChIP)?</li> <li>The Coverage Check: Do we have enough reads? Are they duplicates?</li> <li>The Family Tree (Correlation &amp; PCA): Do biological replicates (siblings) look similar? Are they distinct from the control?</li> </ul> <p>We use a suite of tools called deepTools to generate these reports.</p>"},{"location":"10_bam_summary_fingerprint/#2-running-the-qc-of-bam-files-before-peak-calling","title":"2. Running the QC of bam files before Peak Calling","text":"<p>[!IMPORTANT] About ENCODE BAM files: The ENCODE BAM files used in this tutorial are already pre-processed (see Section 08). They have been deduplicated and filtered for mapping quality (MAPQ \u2265 30), meaning multimappers have been removed.</p> <p>All outputs will be saved to the <code>deeptools_qc/</code> directory for organization.</p>"},{"location":"10_bam_summary_fingerprint/#21-fingerprint-plot","title":"2.1 Fingerprint Plot","text":"<p>Requirements: BAM files in <code>encode_bam/</code> directory.</p> <pre><code># Create output directory\nmkdir -p deeptools_qc\n\nplotFingerprint \\\n  -b encode_bam/ceb_ENCFF327JFG.bam encode_bam/H3K9ac_ENCFF193NPE.bam encode_bam/Input_ENCFF110SOB.bam \\\n  --skipZeros \\\n  --numberOfSamples 50000 \\\n  -T \"Fingerprints of all BAM samples\" \\\n  --plotFile deeptools_qc/fingerprints.pdf \\\n  --plotFileFormat pdf \\\n  --dpi 600 \\\n  2&gt;&amp;1 | tee deeptools_qc/plotFingerprint.log\n</code></pre> <p>What this does: Samples 50,000 random genomic positions and plots cumulative read distribution to assess IP enrichment. ChIP samples should show strong enrichment (steep curve), while Input should follow the diagonal.</p>"},{"location":"10_bam_summary_fingerprint/#22-coverage-plot","title":"2.2 Coverage Plot","text":"<p>Checks sequencing depth and duplication levels.</p> <pre><code>plotCoverage \\\n  -b encode_bam/ceb_ENCFF327JFG.bam encode_bam/H3K9ac_ENCFF193NPE.bam encode_bam/Input_ENCFF110SOB.bam \\\n  -o deeptools_qc/coverage_histogram.pdf \\\n  --plotFileFormat pdf \\\n  --dpi 600 \\\n  --smartLabels \\\n  --numberOfSamples 1000000 \\\n  --ignoreDuplicates \\\n  --minMappingQuality 30 \\\n  --outRawCounts deeptools_qc/coverage_counts.txt\n</code></pre> <p>What this does: Samples 1 million genomic positions and plots coverage distribution. The <code>--ignoreDuplicates</code> and <code>--minMappingQuality 30</code> flags document expected data quality (ENCODE BAMs are already filtered, so these serve as safety checks).</p>"},{"location":"10_bam_summary_fingerprint/#23-summary-matrix","title":"2.3 Summary Matrix","text":"<p>We need a \"Count Matrix\" to compare samples. This counts reads in bins across the whole genome.</p> <pre><code>multiBamSummary bins \\\n  -b encode_bam/ceb_ENCFF327JFG.bam encode_bam/ceb_ENCFF744SVA.bam \\\n     encode_bam/H3K27me3_ENCFF164ALR.bam encode_bam/H3K27me3_ENCFF532DQH.bam \\\n     encode_bam/H3K9ac_ENCFF193NPE.bam encode_bam/H3K9ac_ENCFF534IPX.bam \\  # Input BAM files (IP samples only)\n  --numberOfProcessors 4 \\                       # Run on 4 CPUs to speed up processing\n  -o deeptools_qc/matrix.npz \\                   # Output compressed matrix file (for plotting)\n  --outRawCounts deeptools_qc/matrix.tab         # Output tab-separated counts file (readable text)\n</code></pre> <p>What this does: Divides the genome into bins and counts reads per bin for each sample, creating a matrix used by correlation and PCA analysis. We exclude Input samples to focus on comparing ChIP enrichment patterns.</p>"},{"location":"10_bam_summary_fingerprint/#24-correlation-pca","title":"2.4 Correlation &amp; PCA","text":"<p>Using the matrix from Step 2.3, we compare the samples.</p> <p>Correlation Heatmap:</p> <pre><code>plotCorrelation \\\n  -in deeptools_qc/matrix.npz \\                  # Input matrix from multiBamSummary\n  --corMethod spearman \\                         # Use Spearman correlation (robust to outliers)\n  --skipZeros \\                                  # Ignore bins with zero reads\n  --whatToPlot heatmap \\                         # Generate a heatmap (vs scatterplot)\n  --colorMap RdYlBu \\                            # Color map (Red-Yellow-Blue)\n  --plotNumbers \\                                # Show correlation coefficients on plot\n  --plotTitle \"Spearman correlation of binned genome coverage\" \\ # Title\n  --dpi 600 \\                                    # High resolution for publication quality\n  -o deeptools_qc/spearman_corr_plot.pdf \\       # Output PDF file\n  --outFileCorMatrix deeptools_qc/spearman_corr_plot.tab  # Save correlation values to text file\n</code></pre> <p>What this does: Computes pairwise Spearman correlation between samples using the count matrix. Biological replicates should show high correlation, and different marks/TFs should cluster separately.</p> <p>PCA (Principal Component Analysis):</p> <pre><code>plotPCA \\\n  -in deeptools_qc/matrix.npz \\                  # Input matrix from multiBamSummary\n  -o deeptools_qc/pca.pdf \\                      # Output PDF file\n  -T \"PCA of samples based on binned genome coverage\" \\ # Title\n  --transpose \\                                  # Transpose matrix (required for correct grouping)\n  --plotWidth 14 \\                               # Width of the plot in inches\n  --plotHeight 12 \\                              # Height of the plot in inches\n  --plotFileFormat pdf \\                         # File format\n  --dpi 600 \\                                    # High resolution for publication quality\n  --outFileNameData deeptools_qc/pca.tab \\       # Save PCA coordinates to text file\n  --markers 's' 's' 'D' 'D' 'o' 'o' \\            # Markers for each sample (pairs share markers)\n  --colors  '#1b9e77' '#66c2a5' \\                # Colors for ceb replicates (Green)\n            '#d95f02' '#fc8d62' \\                # Colors for H3K27me3 replicates (Orange)\n            '#7570b3' '#8da0cb'                  # Colors for H3K9ac replicates (Purple)\n</code></pre> <p>What this does: Reduces high-dimensional count data to 2D for visualization. Samples should cluster by biological condition, with replicates grouping together and distinct marks/TFs separating along principal components.</p> <p>Using <code>sample_id.txt</code> for dynamic BAM file lists:</p> <p>Requirements: You need <code>sample_id.txt</code> file containing sample IDs (one per line, created in section 08).</p> <pre><code># Create BAM file paths from sample IDs\nBAM_FILES=$(while read sample; do echo \"encode_bam/${sample}.bam\"; done &lt; sample_id.txt | tr '\\n' ' ')\n\n# Create labels from basenames (for cleaner plot labels)\nLABELS=$(cat sample_id.txt | tr '\\n' ' ')\n\n# For IP samples only (excludes Input controls)\nIP_FILES=$(grep -v \"Input\" sample_id.txt | while read sample; do echo \"encode_bam/${sample}.bam\"; done | tr '\\n' ' ')\nIP_LABELS=$(grep -v \"Input\" sample_id.txt | tr '\\n' ' ')\n\n# Echo commands to verify what we built\necho \"All BAM files:\"\necho $BAM_FILES\necho \"\"\necho \"All labels:\"\necho $LABELS\necho \"\"\n</code></pre> <p>What this script does (line-by-line):</p> <p>For all samples (<code>BAM_FILES</code> and <code>LABELS</code>):</p> <ol> <li> <p><code>BAM_FILES=...</code> - Reads <code>sample_id.txt</code>, loops through each sample ID, prepends <code>encode_bam/</code> and appends <code>.bam</code>, then converts newlines to spaces. Result: space-separated list of full BAM file paths.</p> </li> <li> <p><code>LABELS=...</code> - Reads <code>sample_id.txt</code> and converts newlines to spaces. Result: space-separated list of sample IDs (basenames) for cleaner plot labels.</p> </li> </ol> <p>For IP samples only (<code>IP_FILES</code> and <code>IP_LABELS</code>):</p> <p>The same logic applies, but <code>grep -v \"Input\"</code> filters out Input control samples first, creating IP-only file and label lists for correlation/PCA analysis.</p> <p>Echo demonstrations for <code>BAM_FILES</code> and <code>LABELS</code>:</p> <pre><code>echo \"All BAM files:\"\necho $BAM_FILES\necho \"\"\necho \"All labels:\"\necho $LABELS\n</code></pre> <p>Expected output:</p> <pre><code>All BAM files:\n\nencode_bam/ceb_ENCFF327JFG.bam encode_bam/ceb_ENCFF744SVA.bam encode_bam/H3K27me3_ENCFF164ALR.bam encode_bam/H3K27me3_ENCFF532DQH.bam encode_bam/H3K9ac_ENCFF193NPE.bam encode_bam/H3K9ac_ENCFF534IPX.bam encode_bam/Input_ENCFF110SOB.bam encode_bam/Input_ENCFF919XCV.bam\n\nAll labels:\nceb_ENCFF327JFG ceb_ENCFF744SVA H3K27me3_ENCFF164ALR H3K27me3_ENCFF532DQH H3K9ac_ENCFF193NPE H3K9ac_ENCFF534IPX Input_ENCFF110SOB Input_ENCFF919XCV\n</code></pre> <p>The basenames (labels) produce cleaner plot legends compared to full file paths.</p> <p>Example usage with labels:</p> <pre><code># Use with plotFingerprint\nplotFingerprint -b $BAM_FILES --labels $LABELS --skipZeros ...\n\n# Use with multiBamSummary (IP samples only)\nmultiBamSummary bins -b $IP_FILES --labels $IP_LABELS ...\n</code></pre>"},{"location":"10_bam_summary_fingerprint/#level-3-reading-the-charts","title":"Level 3: Reading the Charts","text":""},{"location":"10_bam_summary_fingerprint/#31-interpreting-the-fingerprint-the-census","title":"3.1 Interpreting the Fingerprint (The Census)","text":"<p>This plot shows the cumulative read distribution across the genome. Good ChIP libraries show a clear separation between ChIP and input samples, with ChIP curves rising earlier due to enriched regions. Flat, overlapping curves usually indicate poor enrichment or over-background signal.</p> <p></p> Sample Type Interpretation Input Close to the diagonal. Reads are uniformly distributed, behaving like ideal background. H3K9ac Strong \"Elbow\". Reads concentrated in a small fraction of bins (focal peaks), showing a strong bend away from the diagonal."},{"location":"10_bam_summary_fingerprint/#32-interpreting-coverage","title":"3.2 Interpreting Coverage","text":"<p>Next, we look at the overall coverage distribution in each BAM using plotCoverage. This reveals whether some samples are globally under-sequenced, dominated by a few high-coverage regions, or heavily affected by duplicated reads. We restrict to high-quality, non-duplicate reads to make the distributions comparable.</p> <p>Plot A: The Drop-off</p> <ul> <li> <p>Inputs : The Input tracks sit higher at low coverage because they spread their reads across the genome without enrichment. That\u2019s why both Input samples show a large fraction of bases at coverage 0 and 1, then taper off more slowly as coverage increases.</p> </li> <li> <p>ChIPs : In contrast, every IP sample collapses more sharply; the curves drop faster after coverage 1 because most genomic positions in a ChIP experiment receive almost no reads. Only a small portion of the genome \u2014 the actual binding or modification sites \u2014 reaches deeper coverage, and that fraction is tiny enough that the tail beyond coverage 2 nearly vanishes.</p> </li> </ul> <p></p> <p>Plot B: The Tail Zooming in reveals the difference. Input covers more of the genome at 1x depth, while ChIP focuses on peaks. The Input curves decline more slowly because a larger fraction of their genome maintains at least some measurable coverage. The IP curves fall off earlier and more steeply, which reflects the enrichment pattern: most positions have essentially no reads, and only a very small subset of bases in true peak regions sustain higher coverage.</p> <p></p>"},{"location":"10_bam_summary_fingerprint/#33-interpreting-correlation-the-family-tree","title":"3.3 Interpreting Correlation (The Family Tree)","text":"<p>Using the binned count matrix, we compute pairwise correlations between samples. A Spearman correlation heatmap shows whether biological replicates cluster together and whether inputs are distinct from ChIP samples. Poor clustering or scattered correlations usually indicate sample swaps, failed IPs, or inconsistent library prep.</p> <p>The Heatmap:</p> <ul> <li>Clustering: H3K27me3 samples cluster together and show moderately high mutual correlations (around 0.6), which is exactly what you expect for a broad repressive mark. The H3K9ac samples also correlate strongly with each other (0.76\u20131.0), forming a clean sub-cluster that is distinct from H3K27me3.</li> <li>Separation: Active marks (H3K9ac) should look different from Repressive marks (H3K27me3).</li> </ul> <p></p>"},{"location":"10_bam_summary_fingerprint/#34-interpreting-pca","title":"3.4 Interpreting PCA","text":"<p>Finally, we perform PCA on the same binned count matrix. PCA reduces the data to a few dimensions that capture most of the variance. In a good ChIP-seq dataset, biological replicates cluster together in PCA space, and distinct conditions or marks separate along major components. PCA is a convenient visual check for batch effects, sample swaps, and outlier libraries.</p> <p>The Map:</p> <ul> <li>PC1 (X-axis): The PCA shows clear separation of samples by assay type. PC1 captures most of the variance and cleanly splits the H3K27me3 group from the H3K9ac group, which is expected because these marks have very different genomic distributions.</li> <li>Clustering: The two \u201cceb\u201d samples cluster tightly together, indicating consistent coverage patterns within that group. The H3K27me3 replicates are also tightly paired, which matches their broad and uniform enrichment profile. The H3K9ac replicates sit on the opposite side of PC1, with one replicate shifted slightly on PC2, hinting at a mild difference in coverage distribution but nothing severe. If one replicate is far away, it might be an outlier/bad sample.</li> </ul> <p></p>"},{"location":"10_bam_summary_fingerprint/#directory-structure-after-deeptools-qc","title":"Directory Structure After deepTools QC","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 encode_bam/                  \u2190 ENCODE BAM files\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG.bam\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE.bam\n\u2502   \u2514\u2500\u2500 ...                      (8 BAM files total)\n\u251c\u2500\u2500 encode_bam_qc/               \u2190 QC from section 08\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 spp_qc/                      \u2190 QC from section 09\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 deeptools_qc/                \u2190 deepTools outputs\n\u2502   \u251c\u2500\u2500 fingerprints.pdf\n\u2502   \u251c\u2500\u2500 plotFingerprint.log\n\u2502   \u251c\u2500\u2500 coverage_histogram.pdf\n\u2502   \u251c\u2500\u2500 coverage_counts.txt\n\u2502   \u251c\u2500\u2500 matrix.npz\n\u2502   \u251c\u2500\u2500 matrix.tab\n\u2502   \u251c\u2500\u2500 spearman_corr_plot.pdf\n\u2502   \u251c\u2500\u2500 spearman_corr_plot.tab\n\u2502   \u251c\u2500\u2500 pca.pdf\n\u2502   \u2514\u2500\u2500 pca.tab\n\u2514\u2500\u2500 sample_id.txt\n</code></pre>"},{"location":"10_bam_summary_fingerprint/#summary","title":"Summary","text":"<ol> <li>Fingerprint: Confirms your IP worked (Sharp elbow).</li> <li>Coverage: Confirms sequencing depth (Inputs = broad, ChIP = peaky).</li> <li>PCA/Correlation: Confirms your replicates match (Siblings cluster together).</li> </ol> <p>[!NOTE] Up Next: With comprehensive QC validation complete, we're ready to call peaks with MACS2 and identify protein-DNA bindin sites.</p>"},{"location":"11_macs3_peak_calling/","title":"Peak Calling with MACS3 (The Summit Search)","text":"<p><code>MACS3</code> <code>peak-calling</code> <code>ChIP-seq</code> <code>narrow-peaks</code> <code>broad-peaks</code> <code>p-value</code> <code>transcription-factors</code></p>"},{"location":"11_macs3_peak_calling/#1-basic-concept-the-heap-hunt","title":"1. Basic Concept (The \"Heap\" Hunt)","text":""},{"location":"11_macs3_peak_calling/#what-is-a-peak","title":"What is a Peak?","text":"<p>Imagine you are looking for hidden treasure on a long beach (the Genome).</p> <ul> <li>Random Reads: Sand scattered everywhere evenly (Background noise).</li> <li>A \"Peak\": A huge heap of sand in one specific spot.</li> </ul> <p>This heap means thousands of protein molecules were bound to that exact spot of DNA.</p>"},{"location":"11_macs3_peak_calling/#signal-vs-noise","title":"Signal vs. Noise","text":"<ul> <li>Signal: The Heap (Peak).</li> <li>Noise: The random thin layer of sand everywhere else (Input/Control).</li> </ul> <p>MACS3 is the software that scans the beach, measures the height of the sand pile, and calculates if it is \"significantly\" higher than the background.</p>"},{"location":"11_macs3_peak_calling/#narrow-vs-broad-peaks","title":"Narrow vs. Broad Peaks","text":"<p>Different histone modifications and chromatin marks create distinct peak shapes based on their biological function:</p> <p></p>"},{"location":"11_macs3_peak_calling/#from-encode","title":"(from: Encode)","text":""},{"location":"11_macs3_peak_calling/#2-requirements","title":"2. Requirements","text":""},{"location":"11_macs3_peak_calling/#input-files","title":"Input Files","text":"<p>You need the following files in your workspace:</p> <p>BAM files: Located in <code>encode_bam/</code> directory</p> <p>[!IMPORTANT] ENCODE Pre-processing: These BAM files from ENCODE are already deduplicated and filtered for mapping quality (MAPQ \u2265 30). This is documented in Tutorial 10. You do NOT need to run additional filtering.</p>"},{"location":"11_macs3_peak_calling/#3-execution-step-by-step","title":"3. Execution (Step-by-Step)","text":"<p>We call peaks on each replicate individually, then assess reproducibility using IDR (Irreproducible Discovery Rate). This is the ENCODE standard workflow.</p>"},{"location":"11_macs3_peak_calling/#step-1-create-output-directory","title":"Step 1: Create Output Directory","text":"<pre><code>mkdir -p macs3_results\n</code></pre>"},{"location":"11_macs3_peak_calling/#step-2-h3k9ac-narrow-peaks-both-replicates","title":"Step 2: H3K9ac (Narrow Peaks) - Both Replicates","text":"<p>H3K9ac (Acetylation) creates sharp, tall spikes at active promoters and enhancers.</p> <p>Replicate 1:</p> <pre><code>macs3 callpeak \\\n  -t encode_bam/H3K9ac_ENCFF534IPX.bam \\\n  -c encode_bam/Input_ENCFF110SOB.bam \\\n  -f BAM \\\n  -g hs \\\n  -n H3K9ac_ENCFF534IPX \\\n  -p 0.01 \\\n  --keep-dup all \\\n  --outdir macs3_results\n</code></pre> <p>Replicate 2:</p> <pre><code>macs3 callpeak \\\n  -t encode_bam/H3K9ac_ENCFF193NPE.bam \\\n  -c encode_bam/Input_ENCFF919XCV.bam \\\n  -f BAM \\\n  -g hs \\\n  -n H3K9ac_ENCFF193NPE \\\n  -p 0.01 \\\n  --keep-dup all \\\n  --outdir macs3_results\n</code></pre>"},{"location":"11_macs3_peak_calling/#expected-outputs","title":"Expected Outputs","text":"<p>After running MACS3, you will have:</p> <pre><code>macs3_results/\n\u251c\u2500\u2500 H3K9ac_ENCFF534IPX_peaks.narrowPeak\n\u251c\u2500\u2500 H3K9ac_ENCFF534IPX_peaks.xls\n\u251c\u2500\u2500 ... (similar files for all 6 replicates)\n\u2514\u2500\u2500 H3K9ac_idr_peaks.txt        # After IDR analysis\n</code></pre> <p>Parameter Explanation:</p> <ul> <li><code>-t</code>: Treatment file (IP sample - the enriched DNA).</li> <li><code>-c</code>: Control file (Input - background DNA).</li> <li><code>-f BAM</code>: Input file format.</li> <li><code>-g hs</code>: Genome size (<code>hs</code> = human ~2.7Gb, can also use numeric <code>2.7e9</code> or <code>2.9e9</code> for hg38).</li> <li><code>-n</code>: Output file prefix (use the ENCODE accession for clarity).</li> <li><code>-p 0.01</code>: P-value cutoff. Keep only peaks with p-value &lt; 0.01 (1% significance threshold).</li> <li>Why <code>-p</code> instead of <code>-q</code>? We use IDR (Irreproducible Discovery Rate)  to filter for reproducible peaks between replicates. Starting with lenient <code>-p</code> thresholds captures more candidate peaks, then IDR applies stringent reproducibility filtering. This \"liberal discovery + stringent validation\" approach is standard for replicated ChIP-seq.</li> <li><code>--keep-dup all</code>: For deduplicated BAM files (duplicates already removed). Use <code>--keep-dup 1</code> if BAMs still contain duplicates.</li> <li><code>--outdir</code>: Output directory.</li> </ul> <p>Optional Parameters:</p> <ul> <li> <p><code>-B</code> or <code>--bdg</code>: Generate bedGraph files for fragment pileup and control lambda.</p> </li> <li> <p><code>--bdg --SPMR</code>: Combine with <code>-B</code> to normalize bedGraph by signal per million reads (SPMR)</p> </li> <li> <p><code>-f BAMPE</code>: Explicitly specify paired-end BAM format (BAMPE = BAM with PE alignment)</p> </li> <li> <p><code>--nomodel --extsize &lt;size&gt;</code>: Override automatic fragment size estimation (only needed if model building fails)</p> </li> </ul> <p>[!NOTE] Summit positions for motif analysis: This tutorial does not use <code>--call-summits</code> in MACS3 because precise summit positions will be extracted during IDR analysis , where we identify reproducible peaks and derive consensus summits for motif discovery.</p>"},{"location":"11_macs3_peak_calling/#step-3-h3k27me3-broad-peaks-both-replicates","title":"Step 3: H3K27me3 (Broad Peaks) - Both Replicates","text":"<p>H3K27me3 (Trimethylation) creates wide, gentle hills marking repressed chromatin domains.</p> <p>Replicate 1:</p> <pre><code>macs3 callpeak \\\n  -t encode_bam/H3K27me3_ENCFF532DQH.bam \\\n  -c encode_bam/Input_ENCFF110SOB.bam \\\n  -f BAM \\\n  -g hs \\\n  -n H3K27me3_ENCFF532DQH \\\n  --broad -p 0.01\\\n  --keep-dup all \\\n  --outdir macs3_results\n</code></pre> <p>Replicate 2:</p> <pre><code>macs3 callpeak \\\n  -t encode_bam/H3K27me3_ENCFF164ALR.bam \\\n  -c encode_bam/Input_ENCFF919XCV.bam \\\n  -f BAM \\\n  -g hs \\\n  -n H3K27me3_ENCFF164ALR \\\n   --broad -p 0.01\\\n  --keep-dup all \\\n  --outdir macs3_results\n</code></pre>"},{"location":"11_macs3_peak_calling/#step-4-cebpa-narrow-peaks-transcription-factor-both-replicates","title":"Step 4: CEBPA (Narrow Peaks - Transcription Factor) - Both Replicates","text":"<p>Transcription factors like CEBPA bind to very specific DNA sequences, creating extremely sharp peaks.</p> <p>Replicate 1:</p> <pre><code>macs3 callpeak \\\n  -t encode_bam/ceb_ENCFF327JFG.bam \\\n  -c encode_bam/Input_ENCFF110SOB.bam \\\n  -f BAM \\\n  -g hs \\\n  -n ceb_ENCFF327JFG \\\n  -p 0.01 \\\n  --keep-dup all \\\n  --outdir macs3_results\n</code></pre> <p>Replicate 2:</p> <pre><code>macs3 callpeak \\\n  -t encode_bam/ceb_ENCFF744SVA.bam \\\n  -c encode_bam/Input_ENCFF919XCV.bam \\\n  -f BAM \\\n  -g hs \\\n  -n ceb_ENCFF744SVA \\\n  -p 0.01 \\\n  --keep-dup all \\\n  --outdir macs3_results\n</code></pre>"},{"location":"11_macs3_peak_calling/#4-understanding-the-outputs","title":"4. Understanding the Outputs","text":"<p>After running the commands, inspect <code>macs3_results/</code>. For each sample, you'll see:</p>"},{"location":"11_macs3_peak_calling/#file-types","title":"File Types","text":""},{"location":"11_macs3_peak_calling/#1-_peaksnarrowpeak-or-_peaksbroadpeak-bed6-4-10-cols-narrow-and-bed6-3-9-cols-broad","title":"1. <code>*_peaks.narrowPeak</code> (or <code>*_peaks.broadPeak</code>)  [BED6 + 4 (10 cols) narrow and BED6 + 3 (9 cols) broad]","text":"<ul> <li>What is it? The final list of called peaks.</li> <li>Format: BED-like format with 10 columns:</li> <li>Columns 1-3: Chromosome, start, end</li> <li>Column 4: Peak name</li> <li>Column 5: Integer score (for display)</li> <li>Column 6: Strand (always <code>.</code> for ChIP-seq)</li> <li>Column 7: Fold enrichment</li> <li>Column 8: -log10(p-value)</li> <li>Column 9: -log10(q-value)</li> <li>Column 10: Summit position (relative to start)</li> <li>Use: Open in IGV or use for downstream analysis (annotation, motif finding).</li> </ul> <p>View the file:</p> <pre><code>rajaishaqnabikhan@Rajas-MacBook-Pro bws % head -4 macs3_results/H3K9ac_ENCFF193NPE_peaks.narrowPeak\n\nchr1 777980 778754 H3K9ac_ENCFF193NPE_peak_1a 67 . 3.55173 8.65761 6.72906 109\nchr1 777980 778754 H3K9ac_ENCFF193NPE_peak_1b 473 . 9.73436 49.6911 47.3476 508\nchr1 778874 779368 H3K9ac_ENCFF193NPE_peak_2 254 . 7.6257 27.596 25.4103 313\nchr1 826684 827604 H3K9ac_ENCFF193NPE_peak_3 975 . 18.662 100.173 97.5777 717\n</code></pre> <p>Interpreting the columns:</p> <ul> <li>Peak <code>H3K9ac_ENCFF193NPE_peak_3</code> has the highest score (975) and fold enrichment (18.7x)</li> <li>Column 10 (e.g., 717 for peak_3) is the summit offset: summit is at position 826684+717 = 827401</li> </ul>"},{"location":"11_macs3_peak_calling/#3-_peaksxls","title":"3. <code>*_peaks.xls</code>","text":"<ul> <li>What is it? Excel-friendly table with detailed peak statistics.</li> <li>Contents: All peak coordinates plus:</li> <li><code>fold_enrichment</code>: How many times higher than background (e.g., 10.5 = 10.5x enrichment)</li> <li><code>-log10(pvalue)</code>: Statistical significance (higher = more significant)</li> <li><code>-log10(qvalue)</code>: FDR-corrected p-value (accounts for multiple testing)</li> <li>Use: Filter peaks, rank by significance, extract statistics for publication.</li> </ul> <p>Example interpretation:</p> <pre><code>Peak with fold_enrichment=15.3, -log10(qvalue)=50.2\n\u2192 Signal is 15.3x higher than background\n\u2192 q-value = 10^-50.2 \u2248 6.3e-51 (extremely significant!)\n</code></pre>"},{"location":"11_macs3_peak_calling/#4-_modelr-narrow-peaks-only","title":"4. <code>*_model.r</code> (narrow peaks only)","text":"<ul> <li>What is it? R script that generates a PDF showing the shift model.</li> <li>Use: QC visualization showing fragment length estimation.</li> <li> <p>How to use:</p> <pre><code>Rscript macs3_results/H3K9ac_ENCFF534IPX_model.r &gt;  macs3_results/H3K9ac_ENCFF534IPX_mode.pdf\n</code></pre> </li> </ul>"},{"location":"11_macs3_peak_calling/#directory-structure-after-peak-calling","title":"Directory Structure After Peak Calling","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 encode_bam/                  \u2190 ENCODE BAM files (input)\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF534IPX.bam\n\u2502   \u251c\u2500\u2500 H3K27me3_ENCFF532DQH.bam\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG.bam\n\u2502   \u2514\u2500\u2500 ...                      (\n\u251c\u2500\u2500 deeptools_qc/                \u2190 QC from deeptools\n\u2502   \u251c\u2500\u2500 fingerprints.pdf\n\u2502   \u251c\u2500\u2500 coverage_histogram.pdf\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 macs3_results/               \u2190 MACS3 outputs\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_peaks.narrowPeak\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_peaks.xls\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_summits.bed\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_model.r\n    \u251c\u2500\u2500 H3K27me3_ENCFF532DQH_peaks.broadPeak\n    \u251c\u2500\u2500 H3K27me3_ENCFF532DQH_peaks.xls\n    \u251c\u2500\u2500 ceb_ENCFF327JFG_peaks.narrowPeak\n    \u251c\u2500\u2500 ceb_ENCFF327JFG_peaks.xls\n    \u2514\u2500\u2500 ...                       \n</code></pre>"},{"location":"11_macs3_peak_calling/#summary","title":"Summary","text":"<p>You have successfully called peaks using MACS3 for:</p> <ol> <li>H3K9ac (narrow peaks, active histone mark)</li> <li>H3K27me3 (broad peaks, repressive mark)</li> <li>CEBPA (narrow peaks, transcription factor)</li> </ol> <p>Peak calling strategy:</p> <ul> <li>Used <code>-p 0.01</code> for lenient discovery (captures candidate peaks)</li> <li>Will apply IDR filtering in Tutorial 13 for stringent validation</li> <li>No <code>--call-summits</code> here - summits extracted during IDR analysis</li> </ul> <p>[!NOTE] Up Next: Calculate FRiP (Fraction of Reads in Peaks) quality metrics to validate peak enrichment, then assess reproducibility with IDR and perform motif discovery.</p>"},{"location":"11_macs3_peak_calling/#directory-structure-after-peak-calling_1","title":"Directory Structure After Peak Calling","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 bam_files_final/            \u2190 Filtered BAM files\n\u2514\u2500\u2500 macs3_results/              \u2190 **NEW: MACS3 peak calling outputs**\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_peaks.narrowPeak\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_peaks.xls\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_summits.bed\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_model.r\n    \u251c\u2500\u2500 H3K9ac_ENCFF193NPE_peaks.narrowPeak\n    \u251c\u2500\u2500 H3K9ac_ENCFF193NPE_peaks.xls\n    \u251c\u2500\u2500 H3K9ac_ENCFF193NPE_summits.bed\n    \u2514\u2500\u2500 H3K9ac_ENCFF193NPE_model.r\n</code></pre>"},{"location":"12_frip_quality_metrics/","title":"Quality Metrics - FRiP (Fraction of Reads in Peaks)","text":"<p><code>FRiP</code> <code>quality-control</code> <code>ChIP-seq</code> <code>ENCODE-standards</code> <code>peak-calling</code> <code>QC-metrics</code></p>"},{"location":"12_frip_quality_metrics/#background","title":"Background","text":"<p>Having called peaks with MACS3, we now quantify ChIP enrichment quality using FRiP (Fraction of Reads in Peaks). FRiP measures the proportion of sequencing reads that overlap called peak regions versus background.</p> <p>In successful ChIP-seq experiments, immunoprecipitation selectively enriches DNA fragments bound by the target protein, causing a substantial fraction of reads to concentrate in peak regions. The remainder represents genomic background from non-specific binding or incomplete washing. By contrast, failed experiments show most reads distributed evenly across the genome, yielding low FRiP values.</p> <p>FRiP thus provides a rapid, quantitative metric for immunoprecipitation efficiency\u2014high FRiP indicates successful enrichment, while low FRiP flags potential technical problems before investing effort in downstream analysis.</p>"},{"location":"12_frip_quality_metrics/#1-what-is-frip","title":"1. What is FRiP?","text":"<p>FRiP measures how much of your ChIP signal is concentrated in called peaks. It's a key ENCODE quality metric.</p>"},{"location":"12_frip_quality_metrics/#calculating-frip","title":"Calculating FRiP","text":"<p>Formula: FRiP = (Reads in peaks) / (Total mapped reads)</p> <p>Input files:</p> <ul> <li>BAM file: <code>encode_bam/ceb_ENCFF327JFG.bam</code> (deduplicated, MAPQ filtered)</li> <li>Peak file: <code>macs3_results/ceb_ENCFF327JFG_peaks.narrowPeak</code></li> </ul> <p>Complete FRiP calculation script:</p> <pre><code># Step 1: Count total mapped reads\nTOTAL_READS=$(samtools view -c encode_bam/ceb_ENCFF327JFG.bam)\n</code></pre> <p>This command counts the total number of alignments in the BAM file. Since the BAM is already deduplicated and MAPQ-filtered, this value represents the total number of mapped reads, which serves as the denominator in the FRiP calculation.</p> <pre><code># Step 2: Merge overlapping peak regions (avoid double-counting)\nmkdir -p frip_analysis\nsort -k1,1 -k2,2n macs3_results/ceb_ENCFF327JFG_peaks.narrowPeak | \\\n  bedtools merge -i stdin &gt; frip_analysis/ceb_ENCFF327JFG.peaks.merged.bed\n</code></pre> <p>MACS3 peak files may contain overlapping or adjacent peak regions. To avoid double-counting reads that overlap multiple nearby peaks, all peak intervals are first sorted and then merged into a non-redundant set of regions. This step ensures that each read contributes at most once to the FRiP numerator.</p> <pre><code># Step 3: Count reads overlapping peaks (unique reads only)\nREADS_IN_PEAKS=$(\n  samtools view -b encode_bam/ceb_ENCFF327JFG.bam | \\\n  bedtools intersect -u -a stdin -b frip_analysis/ceb_ENCFF327JFG.peaks.merged.bed | \\\n  samtools view -c\n)\n</code></pre> <p>Aligned reads from the BAM file are intersected with the merged peak regions. The <code>-u</code> option ensures that each read is counted only once, even if it overlaps more than one peak interval. The resulting count corresponds to the number of unique reads that fall within CEBPA peak regions.</p> <pre><code># Step 4: Calculate the FRiP score\nFRIP=$(awk -v n=\"${READS_IN_PEAKS}\" -v d=\"${TOTAL_READS}\" \\\n  'BEGIN {printf \"%.5f\", n/d}')\n</code></pre> <p>The FRiP score is calculated as the ratio of reads overlapping peak regions to the total number of mapped reads. The result is formatted to five decimal places for clarity and consistency.</p>"},{"location":"12_frip_quality_metrics/#complete-frip-calculation-script","title":"Complete FRiP Calculation Script","text":"<p>For convenience, here's the complete executable script combining all steps:</p> <pre><code>#!/bin/bash\n# Complete FRiP calculation for ceb_ENCFF327JFG\nmkdir -p frip_analysis\n\n# Count total reads\nTOTAL_READS=$(samtools view -c encode_bam/ceb_ENCFF327JFG.bam)\n\n# Merge overlapping peaks\nsort -k1,1 -k2,2n macs3_results/ceb_ENCFF327JFG_peaks.narrowPeak | \\\n  bedtools merge -i stdin &gt; frip_analysis/ceb_ENCFF327JFG.peaks.merged.bed\n\n# Count reads in peaks\nREADS_IN_PEAKS=$(samtools view -b encode_bam/ceb_ENCFF327JFG.bam | \\\n  bedtools intersect -u -a stdin -b frip_analysis/ceb_ENCFF327JFG.peaks.merged.bed | \\\n  samtools view -c)\n\n# Calculate FRiP\nFRIP=$(awk -v n=\"${READS_IN_PEAKS}\" -v d=\"${TOTAL_READS}\" 'BEGIN {printf \"%.5f\", n/d}')\n\n# Report results\necho \"Sample: ceb_ENCFF327JFG\"\necho \"Total mapped reads : ${TOTAL_READS}\"\necho \"Reads in peaks     : ${READS_IN_PEAKS}\"\necho \"FRiP               : ${FRIP}\"\n</code></pre>"},{"location":"12_frip_quality_metrics/#expected-output","title":"Expected Output","text":"<p>Results we got:</p> <pre><code>sample total_reads reads_in_peaks FRiP\nceb_ENCFF327JFG 27863042 1511077 0.05423\nceb_ENCFF744SVA 16814770 1187486 0.07062\nH3K27me3_ENCFF164ALR 39952273 11528033 0.28855\nH3K27me3_ENCFF532DQH 35184227 10987930 0.31230\nH3K9ac_ENCFF193NPE 34567738 14283991 0.41322\nH3K9ac_ENCFF534IPX 39792428 6625200 0.16649\n</code></pre>"},{"location":"12_frip_quality_metrics/#interpreting-these-results","title":"Interpreting These Results","text":"<p>Key Observations:</p> <ul> <li>H3K9ac: Replicate discordance (41% vs 17%) needs IDR validation</li> <li>H3K27me3: Excellent concordance (~30%) indicates robust data  </li> <li>CEBPA: Low (5-7%) but acceptable for sparse transcription factors</li> </ul>"},{"location":"12_frip_quality_metrics/#frip-quality-standards","title":"FRiP Quality Standards","text":"<p>ENCODE guidelines (Landt et al. 2012) flag transcription factor experiments with FRiP below ~1%, as such values often reflect weak enrichment or technical failure, while well-defined point-source factors like CTCF or REST frequently achieve FRiP values of 20\u201350%. These expectations are not universal: factors with few binding sites or low occupancy can yield FRiP &lt;1% yet remain biologically valid.</p> <p>Histone marks generally show higher FRiP due to their broader genomic coverage, though acceptable values differ markedly between narrow and broad marks.</p> <p>Because FRiP depends strongly on sequencing depth, peak-calling parameters, and the biological target, it should always be interpreted in conjunction with complementary QC metrics such as fingerprint plots, strand cross-correlation, and coverage profiles, not in isolation.</p>"},{"location":"12_frip_quality_metrics/#directory-structure-after-frip-calculation","title":"Directory Structure After FRiP Calculation","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 encode_bam/                  \u2190 Input BAM files\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG.bam\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 macs3_results/               \u2190 Peak files from MACS3\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG_peaks.narrowPeak\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_peaks.narrowPeak\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 frip_analysis/               \u2190 FRiP working files (optional)\n    \u251c\u2500\u2500 ceb_ENCFF327JFG.peaks.merged.bed\n    \u2514\u2500\u2500 frip_scores.txt\n</code></pre>"},{"location":"12_frip_quality_metrics/#summary","title":"Summary","text":"<p>You've learned how to:</p> <ul> <li>Calculate FRiP (Fraction of Reads in Peaks) quality metrics</li> <li>Interpret FRiP values according to ENCODE guidelines</li> <li>Understand what constitutes good vs. poor ChIP-seq data</li> </ul> <p>[!NOTE] Up Next: Assess reproducibility between replicates using IDR (Irreproducible Discovery Rate) and identify consensus peaks for downstream motif analysis.</p>"},{"location":"12_frip_quality_metrics/#directory-structure-after-frip-calculation_1","title":"Directory Structure After FRiP Calculation","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 bam_files_final/            \u2190 Filtered BAM files\n\u251c\u2500\u2500 macs3_results/              \u2190 Peak files\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_peaks.narrowPeak\n\u2502   \u251c\u2500\u2500 H3K9ac_ENCFF193NPE_peaks.narrowPeak\n\u2502   \u251c\u2500\u2500 H3K27me3_ENCFF164ALR_peaks.broadPeak\n\u2502   \u2514\u2500\u2500 H3K27me3_ENCFF532DQH_peaks.broadPeak\n\u2514\u2500\u2500 frip_results/               \u2190 **NEW: FRiP metrics**\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX_frip.txt\n    \u251c\u2500\u2500 H3K9ac_ENCFF193NPE_frip.txt\n    \u251c\u2500\u2500 H3K27me3_ENCFF164ALR_frip.txt\n    \u2514\u2500\u2500 H3K27me3_ENCFF532DQH_frip.txt\n</code></pre>"},{"location":"13_idr_consensus_motifs_rk_corrected/","title":"Reproducibility Analysis - IDR, Consensus Peaks &amp; Motif Discovery","text":"<p><code>IDR</code> <code>reproducibility</code> <code>consensus-peaks</code> <code>motif-analysis</code> <code>HOMER</code> <code>MEME-ChIP</code> <code>ENCODE</code> <code>peak-filtering</code></p>"},{"location":"13_idr_consensus_motifs_rk_corrected/#1-reproducibility-analysis-idr-irreproducible-discovery-rate","title":"1. Reproducibility Analysis: IDR (Irreproducible Discovery Rate)","text":"<p>IDR (https://github.com/nboley/idr#output-file-format) is a statistical framework used to quantify how consistently peaks are detected between biological replicates. It was developed for large-scale functional genomics projects and is mandated by ENCODE for ChIP-seq reproducibility assessment.</p> <p>IDR models peak rankings between replicates and estimates the probability that a peak is irreproducible noise rather than a real signal.</p>"},{"location":"13_idr_consensus_motifs_rk_corrected/#why-idr-matters","title":"Why IDR Matters","text":"<ul> <li>Peaks unique to one replicate are likely noise</li> <li>Peaks present in both replicates are high-confidence</li> <li>IDR &lt; 0.05 means peaks are reproducible</li> </ul> <p>ENCODE describes two ways to define reproducible peaks using IDR. The conservative approach, used here, runs IDR on true biological replicates and keeps only peaks that agree between independent experiments, giving high-confidence results. The optimal approach runs IDR on pseudoreplicates created by randomly splitting pooled data, which increases sensitivity. In this tutorial, we use the conservative approach with the biological replicates ceb_ENCFF327JFG_peaks and ceb_ENCFF744SVA_peaks.narrowPeak to focus on reproducible peaks.</p>"},{"location":"13_idr_consensus_motifs_rk_corrected/#installing-idr","title":"Installing IDR","text":"<p>Install IDR (if not already installed):</p> <p>IDR has binary and dependency issues on macOS ARM64, and it is recommended to create a dedicated environment to avoid conflicts with other packages.</p> <pre><code>name: idr_env\nchannels:\n  - conda-forge\n  - bioconda\ndependencies:\n  - python=3.9\n  - numpy=1.23.5\n  - scipy=1.10.1\n  - matplotlib=3.7.1\n  - pip\n  - pip:\n      - git+https://github.com/nboley/idr.git\n</code></pre> <pre><code>conda env create -f idr_env.yml\nconda activate idr_env\n</code></pre>"},{"location":"13_idr_consensus_motifs_rk_corrected/#2-running-idr-on-cebpa-replicates","title":"2. Running IDR on CEBPA Replicates","text":"<pre><code>idr --samples \\\n  macs3_results/ceb_ENCFF327JFG_peaks.narrowPeak \\\n  macs3_results/ceb_ENCFF744SVA_peaks.narrowPeak \\\n  --input-file-type narrowPeak \\\n  --rank signal.value \\\n  --output-file idr/ceb_idr_peaks.txt \\\n  --plot \\\n  --log-output-file idr/ceb_idr.log\n</code></pre> <p>Parameter Explanation:</p> <ul> <li><code>--samples</code>: The two replicate peak files</li> <li><code>--rank p.value</code>: Rank peaks by p-value (ENCODE default)</li> <li>Alternatives: <code>signal.value</code> (fold enrichment) or <code>q.value</code> (FDR)</li> <li><code>--plot</code>: Generate diagnostic plots showing replicate concordance</li> <li><code>--log-output-file</code>: Save detailed statistics</li> </ul>"},{"location":"13_idr_consensus_motifs_rk_corrected/#interpreting-idr-output","title":"Interpreting IDR Output","text":"<p>The output file <code>ceb_idr_peaks.txt</code> contains peaks found in both replicates with IDR scores. See the official IDR documentation for complete format details.</p> <p>Key Columns:</p> <p>Columns 1-3 (chr, start, end): Genomic coordinates of the merged peak region where reproducible signal was detected.</p> <p>Column 5 (scaled IDR score): Compressed 0-1000 score for ranking and visualization only (NOT for filtering). Higher values indicate better reproducibility:</p> <ul> <li>IDR = 0 \u2192 score = 1000 (perfect)</li> <li>IDR = 0.05 \u2192 score \u2248 540</li> </ul> <p>Column 7 (signalValue): Strength of ChIP enrichment inherited from MACS3. Reflects signal intensity, not reproducibility.</p> <p>Column 11 (local IDR): Reproducibility score for this specific peak using <code>-log10(IDR)</code> scale.</p> <p>Column 12 (global IDR): Primary ENCODE metric for defining reproducible peaks across replicates, also on <code>-log10(IDR)</code> scale where higher values = better reproducibility:</p> <ul> <li><code>-log10(IDR) \u2265 1.3</code> \u2192 IDR \u2264 0.05 (standard threshold)</li> <li><code>-log10(IDR) \u2265 2.0</code> \u2192 IDR \u2264 0.01 (very stringent)</li> <li>Formula: <code>-log10(0.05) = 1.301 \u2248 1.3</code></li> </ul> <p>Check peak counts at different thresholds:</p> <pre><code># Standard threshold (IDR \u2264 0.05)\nawk '$12 &gt;= 1.3' idr/ceb_idr_peaks.txt | wc -l\n\n# Stringent threshold (IDR \u2264 0.01)\nawk '$12 &gt;= 2.0' idr/ceb_idr_peaks.txt | wc -l\n</code></pre>"},{"location":"13_idr_consensus_motifs_rk_corrected/#filtering-for-reproducible-peaks","title":"Filtering for Reproducible Peaks","text":"<p>Filter peaks that pass the standard IDR threshold:</p> <pre><code>awk '$12 &gt;= 1.3' idr/ceb_idr_peaks.txt &gt; idr/ceb_idr_passed.bed\n</code></pre> <pre><code># Count results\n\n(chip) rajaishaqnabikhan@Rajas-MacBook-Pro bws % wc -l &lt;  idr/ceb_idr_peaks.txt\n    32273\n(chip) rajaishaqnabikhan@Rajas-MacBook-Pro bws % wc -l &lt;  idr/ceb_idr_passed.bed\n     9468\n</code></pre> <p>Interpretation:</p> <p>Roughly 29.3% (9,468/32,273) of initial peaks are reproducible at IDR \u2264 0.05. This is entirely reasonable for a transcription factor ChIP-seq, where we expect only the strongest, most reproducible binding sites to pass stringent filtering.</p>"},{"location":"13_idr_consensus_motifs_rk_corrected/#understanding-idr-diagnostic-plots","title":"Understanding IDR Diagnostic Plots","text":"<p>IDR generates three diagnostic plots to visualize replicate concordance:</p> <p>Plot 1: Rank Consistency Plot</p> <p></p> <p>This plot displays the normalized rank of peaks in replicate 1 (X-axis) versus replicate 2 (Y-axis). Each point represents a peak shared between replicates, with black/gray points indicating reproducible peaks (IDR &lt; 0.05) and red points showing irreproducible peaks (IDR \u2265 0.05). A strong diagonal indicates good replicate concordance, where high-ranking peaks in one replicate are also high-ranking in the other.</p> <p>Plot 2: Signal Consistency Plot</p> <p></p> <p>This log10(signal)-log10(signal) plot compares signal strength between replicates, with black points representing reproducible peaks (IDR &lt; 0.05) and red points showing irreproducible peaks (IDR \u2265 0.05). A tight diagonal band for black points confirms that strong peaks are consistently strong in both replicates, validating the biological signal.</p> <p>Plot 3: IDR vs Peak Rank</p> <p></p> <p>This plot shows peak rank bins for replicate 1 (X-axis, with best peaks on the right) versus -log10(IDR) scores (Y-axis). Individual points represent peaks, with boxplots summarizing IDR distributions within rank bins. The dashed horizontal line marks the IDR = 0.05 cutoff (-log10 \u2248 1.3). A sigmoidal curve where -log10(IDR) increases sharply as peak rank improves indicates that top-ranked peaks have high reproducibility scores, which is expected for quality ChIP-seq data.</p> <p>Example of Poor IDR (Cross-Factor Comparison):</p> <p>This demonstrates poor IDR results when calculated between biologically unrelated samples (CEBPA replicate vs H3K9ac replicate), shown here for illustration purposes only:</p> <p></p>"},{"location":"13_idr_consensus_motifs_rk_corrected/#3-motif-analysis-finding-dna-binding-sequences","title":"3. Motif Analysis: Finding DNA Binding Sequences","text":""},{"location":"13_idr_consensus_motifs_rk_corrected/#why-motif-analysis-matters","title":"Why Motif Analysis Matters","text":"<p>Reproducible peaks answer where the protein binds. Motif analysis answers why it binds there.</p> <ul> <li>Transcription factors bind specific DNA sequences</li> <li>Histone marks do not bind DNA directly</li> <li>Motif enrichment validates biological specificity</li> </ul> <p>Example:</p> <ul> <li>CEBPA: sequence-specific TF</li> <li>H3K9ac: chromatin mark, no intrinsic motif</li> </ul> <p>If a TF ChIP-seq lacks its expected motif, the experiment is suspect.</p>"},{"location":"13_idr_consensus_motifs_rk_corrected/#prerequisites","title":"Prerequisites","text":"<p>You need the genome FASTA file for sequence extraction:</p> <pre><code># Download and extract genome FASTA\nwget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_49/GRCh38.primary_assembly.genome.fa.gz\ngunzip GRCh38.primary_assembly.genome.fa.gz\n</code></pre>"},{"location":"13_idr_consensus_motifs_rk_corrected/#4-motif-discovery-with-homer","title":"4. Motif Discovery with HOMER","text":"<p>HOMER (Hypergeometric Optimization of Motif EnRichment) is the most widely used ChIP-seq motif discovery framework.</p>"},{"location":"13_idr_consensus_motifs_rk_corrected/#installing-homer","title":"Installing HOMER","text":"<p>[!NOTE] macOS ARM64 Users: HOMER may require manual installation. Use the provided <code>install_homer.sh</code> script for streamlined setup.</p>"},{"location":"13_idr_consensus_motifs_rk_corrected/#running-homer-on-idr-peaks","title":"Running HOMER on IDR Peaks","text":"<pre><code># Extract genomic coordinates from IDR peaks\nawk '$12 &gt;= 1.3 {print $1,$2,$3}' OFS=\"\\t\" \\\n  idr/ceb_idr_peaks.txt &gt; idr/ceb_idr_passed.bed\n\n# Run HOMER motif discovery\nfindMotifsGenome.pl \\\n  idr/ceb_idr_passed.bed \\\n  GRCh38.primary_assembly.genome.fa \\\n  idr/cebpa_motifs/ \\\n  -size 200 \\\n  -mask \\\n  -p 8\n</code></pre> <p>Parameter Explanation:</p> <ul> <li><code>idr/ceb_idr_passed.bed</code>: Input peak file (IDR-filtered peaks)</li> <li><code>GRCh38.primary_assembly.genome.fa</code>: Genome assembly</li> <li><code>idr/cebpa_motifs/</code>: Output directory for results</li> <li><code>-size 200</code>: Search \u00b1100bp around peak center (200bp total window)</li> <li><code>-mask</code>: Mask repetitive DNA sequences</li> <li><code>-p 8</code>: Use 8 CPU threads for parallel processing</li> </ul>"},{"location":"13_idr_consensus_motifs_rk_corrected/#interpreting-homer-results","title":"Interpreting HOMER Results","text":"<p>HOMER creates an output directory with:</p> <pre><code>idr/cebpa_motifs/\n\u251c\u2500\u2500 homerResults.html          # Main results page (OPEN THIS)\n\u251c\u2500\u2500 knownResults.html          # Matches to known motifs\n\u251c\u2500\u2500 motif1.logo.png            # Top de novo motif\n\u251c\u2500\u2500 motif2.logo.png\n\u2514\u2500\u2500 motif1.motif               # Position weight matrix\n</code></pre> <p>Example output from CEBPA analysis:</p> <p></p> <p>Interpreting the results:</p> <ul> <li>Rank (1): Top-ranked motif, most strongly enriched among all detected sequences</li> <li>Motif (logo): Canonical C/EBP-family DNA-binding motif (TTGCGCAA/TTGCAT core) indicating specific TF binding</li> <li>P-value (1e\u22122876): Extreme overrepresentation in peaks vs background, statistically highly significant</li> <li>% of Targets (63.39%): Nearly two-thirds of peaks contain this motif, indicating coherent TF-driven peak set</li> <li>% of Background (3.43%): Rare in background regions, demonstrating strong specificity and enrichment</li> <li>STD (30.7 bp vs 64.0 bp): Motif centered near peak summits (targets) vs broadly distributed (background), supporting direct DNA binding</li> <li>Best Match (CEBPE/MA0837.1, 0.963): De novo motif matches known JASPAR CEBPE motif with high confidence</li> <li>Motif File: Provides position weight matrix for reproducibility and downstream scanning</li> </ul>"},{"location":"13_idr_consensus_motifs_rk_corrected/#5-directory-structure-after-idr-motif-analysis","title":"5. Directory Structure After IDR &amp; Motif Analysis","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 macs3_results/              \u2190 Peak files from MACS3\n\u2502   \u251c\u2500\u2500 ceb_ENCFF327JFG_peaks.narrowPeak\n\u2502   \u251c\u2500\u2500 ceb_ENCFF744SVA_peaks.narrowPeak\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 idr/                        \u2190 IDR outputs\n\u2502   \u251c\u2500\u2500 ceb_idr_peaks.txt       # All peaks with IDR scores\n\u2502   \u251c\u2500\u2500 ceb_idr_passed.bed      # Filtered peaks (IDR \u2264 0.05)\n\u2502   \u251c\u2500\u2500 ceb_idr.log             # IDR statistics\n\u2502   \u2514\u2500\u2500 ceb_idr_peaks.txt.png   # Diagnostic plots\n\u2514\u2500\u2500 idr/cebpa_motifs/           \u2190 HOMER motif results\n    \u251c\u2500\u2500 homerResults.html       # Main results page\n    \u251c\u2500\u2500 knownResults.html       # Known motif matches\n    \u251c\u2500\u2500 motif1.logo.png         # Top de novo motif\n    \u2514\u2500\u2500 motif1.motif            # Position weight matrix\n</code></pre>"},{"location":"13_idr_consensus_motifs_rk_corrected/#6-summary","title":"6. Summary","text":"<p>Key Achievements:</p> <ol> <li>Filtered 32,273 peaks \u2192 9,468 reproducible peaks (29.3%) using IDR \u2264 0.05</li> <li>Validated replicate concordance with diagnostic plots</li> <li>Identified canonical C/EBP motif in 63% of peaks (HOMER)</li> <li>Confirmed CEBPA specificity through motif enrichment</li> </ol> <p>Quality Indicators:</p> <p>Good: Strong diagonal in rank-rank plot, ~30% IDR pass rate, expected motif in &gt;50% peaks Poor: Scattered plot, &lt;10% IDR pass rate, no motif enrichment</p> <p>[!NOTE] Up Next: Generate normalized signal tracks (BigWig files) for genome browser visualization and create publication-quality heatmaps showing enrichment patterns around genomic features.</p>"},{"location":"14_bigwig_generation/","title":"Bam to BigWig (Visualizing the Signal)","text":"<p><code>bamCoverage</code> <code>bigWig</code> <code>normalization</code> <code>RPGC</code> <code>effective-genome-size</code> <code>visualization</code></p>"},{"location":"14_bigwig_generation/#1-basic-concept-the-traffic-map","title":"1. Basic Concept (The Traffic Map)","text":""},{"location":"14_bigwig_generation/#why-bigwig","title":"Why BigWig?","text":"<p>A BAM file gives you the location of every single \"car\" (read) on the road. It's massive and slow to load.</p> <p>A BigWig file is like the Google Maps Traffic View. It doesn't show you the individual cars; it just shows you a green, yellow, or red line indicating \"Volume\".</p> <ul> <li>Small &amp; Fast: Compact file size.</li> <li>Visual: Perfect for viewing on a Genome Browser (IGV/UCSC).</li> </ul>"},{"location":"14_bigwig_generation/#2-requirements-effective-genome-size","title":"2. Requirements (Effective Genome Size)","text":"<p>The \"Effective\" size is the part of the genome that is mappable.</p> <ul> <li>Unique Regions: Easy to map.</li> <li>Repetitive Regions: Hard to map, but reads can technically align there (Ambiguous).</li> </ul> <p>Formula 1: Total Raw Length $$ \\text{Total Genome Length} = \\underbrace{\\text{Effective Genome}}{\\text{All Mappable}} + \\underbrace{\\text{N-bases}} $$}</p> <p>Formula 2: Breaking Down \"Effective Genome\" $$ \\text{Effective Genome} = \\underbrace{\\text{Unique Genome}}{\\text{Easy}} + \\underbrace{\\text{Repetitive DNA}} $$}</p>"},{"location":"14_bigwig_generation/#how-we-calculated-it","title":"How we calculated it","text":"<p>There are two main ways to estimate this:</p>"},{"location":"14_bigwig_generation/#method-1-fasize-calculates-general-effective-genome","title":"Method 1: faSize (Calculates General Effective Genome)","text":"<p>The faSize tool counts all non-N bases. This assumes that if a read aligns to a repeat, it still counts as \"mapped\".</p> <p>Step 1.1: Extract chr11 and chr12</p> <pre><code>samtools faidx genome.fasta chr11 chr12 &gt; chr11_chr12.fasta\n</code></pre> <p>Step 1.2: Get statistics</p> <pre><code>faSize chr11_chr12.fasta\n</code></pre> <p>Output:</p> <pre><code>268361931 bases (690373 N's 267671558 real 267671558 upper 0 lower) in 2 sequences inside 1 file\n</code></pre> <p>Step 1.3: Calculate total effective size (non-N)</p> <pre><code>awk '{nonN = $2 - $5; sum += nonN} END {print sum}' chr11_chr11_chr12.faSize.txt\n# Result: 268361931\n</code></pre> <p>Result: <code>268,361,931 bp</code> (Unique + Repetitive)</p>"},{"location":"14_bigwig_generation/#method-2-khmer-calculates-unique-effective-genome","title":"Method 2: khmer (Calculates Unique Effective Genome)","text":"<p>The khmer tool counts only unique k-mers. It strictly ignores repetitive zones.</p> <p>Command:</p> <pre><code>unique-kmers.py -k 21 chr11_chr12.fasta\n</code></pre> <p>Output:</p> <pre><code>(chip) rajaishaqnabikhan@Mac human % unique-kmers.py -k 21 chr11_chr12.fasta\n\n|| This is the script unique-kmers.py in khmer.\n|| You are running khmer version 3.0.0a3\n|| You are also using screed version 1.1.3\n||\n|| If you use this script in a publication, please cite EACH of the following:\n||\n||   * MR Crusoe et al., 2015. https://doi.org/10.12688/f1000research.6924.1\n||   * A. D\u00f6ring et al. https://doi.org:80/10.1186/1471-2105-9-11\n||   * Irber and Brown. https://doi.org/10.1101/056846\n||\n|| Please see http://khmer.readthedocs.io/en/latest/citations.html for details.\n\nEstimated number of unique 21-mers in chr11_chr12.fasta: 220798375\nTotal estimated number of unique 21-mers: 220798375\n</code></pre>"},{"location":"14_bigwig_generation/#the-result","title":"The Result","text":"<ul> <li>Raw length (Method 1: faSize): <code>268,361,931 bp</code> (Unique + Repetitive)</li> <li>Unique length (Method 2: khmer): <code>220,798,375 bp</code> (Unique Only)</li> <li>The Difference: <code>47,563,556 bp</code> of repetitive/unmappable DNA (Ambiguous).</li> </ul>"},{"location":"14_bigwig_generation/#the-decision","title":"The Decision","text":"<p>Which number do we use?</p> <ul> <li>Therefore, we must use the khmer result (<code>Unique Only</code>), because our data does not contain reads mapped to repetitive regions.</li> </ul> <p>[!TIP] Use this number: <code>220798375</code></p>"},{"location":"14_bigwig_generation/#3-execution-the-converter","title":"3. Execution (The Converter)","text":"<p>We use <code>bamCoverage</code> to convert BAM files into BigWig tracks. We will normalize using RPGC (Reads Per Genome Coverage) so all tracks are comparable (1x coverage scale).</p>"},{"location":"14_bigwig_generation/#step-31-create-output-directory","title":"Step 3.1: Create Output Directory","text":"<p>Keep your workspace clean.</p> <pre><code>mkdir -p bigwigs\n</code></pre>"},{"location":"14_bigwig_generation/#step-32-run-bamcoverage-loop","title":"Step 3.2: Run bamCoverage Loop","text":"<p>We process all BAM files using our <code>sample_id.txt</code> list.</p> <pre><code># Loop through each sample ID in the text file\ncat sample_id.txt | while read id; do\n\n  echo \"Generating BigWig for: $id\"\n\n  bamCoverage \\\n    -b encode_bam/${id}.bam \\                    \n    -o bigwigs/${id}.bw \\                        \n    --binSize 10 \\                               \n    --normalizeUsing RPGC \\                      \n    --effectiveGenomeSize 2701495761 \\            \n    --smoothLength 30 \\                          \n    --numberOfProcessors 4 \n\ndone\n</code></pre> <p>What this does:</p> <ol> <li>Reads the BAM file.</li> <li>Chops the genome into 10bp bins (buckets).</li> <li>Counts reads in each bin.</li> <li>Normalizes the count so 1.0 = 1x genome coverage.</li> <li>Smooths the signal (averaging neighbors) to make the peaks look cleaner.</li> <li>Saves the result as a <code>.bw</code> file.</li> </ol>"},{"location":"14_bigwig_generation/#4-fine-tuning-under-the-hood","title":"4. Fine Tuning (Under the Hood)","text":""},{"location":"14_bigwig_generation/#41-bin-size-resolution","title":"4.1 Bin Size (Resolution)","text":"<ul> <li>Concept: Think of this as the Resolution of your image.</li> <li>Small Bin (10bp): \"HD\" resolution. You see every tiny peak, but the file is larger and slower to compute.</li> <li>Large Bin (100bp): \"SD\" resolution. Good for zooming out and looking at broad trends. Faster to process.</li> <li>Decision: For transcription factors (sharp peaks), 10bp is great. For broad histone marks (H3K27me3), 50-100bp is often sufficient. We use 10bp here for high detail.</li> </ul>"},{"location":"14_bigwig_generation/#42-smoothing-blurring-the-photo","title":"4.2 Smoothing (Blurring the Photo)","text":"<ul> <li>Concept: Smoothing averages the signal of nearby bins to reduce \"jumpy\" noise.</li> <li>Why? Raw sequencing data can be pixelated. Smoothing applies a slight blur to make the biological signal (the hill) stand out against the background noise (the grass).</li> <li>Our Setting: <code>--smoothLength 30</code>. This averages the signal over a 30bp window.</li> </ul>"},{"location":"14_bigwig_generation/#43-normalization-the-currency-exchange","title":"4.3 Normalization (The Currency Exchange)","text":"<p>Samples have different sequencing depths.</p> <ul> <li>Sample A: 40 million reads (Rich)</li> <li>Sample B: 20 million reads (Poor)</li> </ul> <p>If we don't fix this, Sample A will look huge just because it has more money (reads). Normalization puts everyone on the same currency.</p> <ul> <li>RPGC (Reads Per Genome Coverage): Preferred for ChIP-seq.</li> <li>Logic: \"What would this signal look like if we had exactly 1x coverage of the genome?\"</li> <li>Why: It creates a standardized \"Currency\" (1x coverage) that makes biological sense. A value of \"5.0\" in the track means \"5 times more reads than random background\".</li> </ul>"},{"location":"14_bigwig_generation/#summary","title":"Summary","text":"<ol> <li>Input: BAM files (<code>encode_bam/</code>).</li> <li>Action: <code>bamCoverage</code> with RPGC normalization.</li> <li>Output: BigWig files (<code>bigwigs/</code>) ready for IGV visualization.</li> </ol> <p>[!NOTE] Up Next: Now that we have our signals (BigWigs) and our QC (Fingerprints) done, we are ready to call peaks! (Wait, technically we usually call peaks before or parallel to visualization, but viewing tracks helps confirm peak calls).</p>"},{"location":"14_bigwig_generation/#directory-structure-after-bigwig-generation","title":"Directory Structure After BigWig Generation","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 bam_files_final/            \u2190 Source BAM files\n\u251c\u2500\u2500 macs3_results/              \u2190 MACS3 peak files\n\u251c\u2500\u2500 idr/                        \u2190 IDR outputs\n\u2514\u2500\u2500 bigwigs/                    \u2190 **NEW: Normalized BigWig tracks**\n    \u251c\u2500\u2500 H3K9ac_ENCFF534IPX.bw\n    \u251c\u2500\u2500 H3K9ac_ENCFF193NPE.bw\n    \u251c\u2500\u2500 H3K27me3_ENCFF164ALR.bw\n    \u251c\u2500\u2500 H3K27me3_ENCFF532DQH.bw\n    \u251c\u2500\u2500 Input_ENCFF110SOB.bw\n    \u2514\u2500\u2500 Input_ENCFF919XCV.bw\n</code></pre>"},{"location":"15_visualization_heatmaps/","title":"Visualization with deepTools (Creating Signal Heatmaps)","text":""},{"location":"15_visualization_heatmaps/#1-basic-concept-camera-modes","title":"1. Basic Concept (Camera Modes)","text":"<p>We want to visualize the \"Average\" pattern of our protein across all genes. To do this, we need to choose our Camera Mode:</p> <ol> <li> <p>Portrait Mode (Reference-Point):</p> <ul> <li>Focus: One specific point (e.g., the Transcription Start Site, TSS).</li> <li>Action: We stand at the TSS and look 3kb upstream and 10kb downstream.</li> <li>Use Case: Great for seeing promoter activity (H3K9ac, Transcription Factors).</li> </ul> </li> <li> <p>Panorama Mode (Scale-Regions):</p> <ul> <li>Focus: The entire gene body.</li> <li>Action: Since genes are different lengths (short vs long), we stretch or compress them all to fit the same \"frame\" (e.g., 5000bp).</li> <li>Use Case: Great for seeing broad marks that cover the whole gene (H3K27me3, H3K36me3).</li> </ul> </li> </ol> <p>The Process:</p> <ol> <li>Prepare the Map (BED): Define where the genes are.</li> <li>Create the Blueprint (Matrix): <code>computeMatrix</code> calculates the numbers.</li> <li>Take the Photo (Plot): <code>plotHeatmap</code> or <code>plotProfile</code> draws the picture.</li> </ol>"},{"location":"15_visualization_heatmaps/#2-the-blueprint-the-photo-basic-requirement","title":"2. The Blueprint &amp; The Photo - Basic requirement","text":""},{"location":"15_visualization_heatmaps/#step-1-download-reference-annotation","title":"Step 1: Download Reference Annotation","text":"<p>We need the GENCODE human genome annotation to define TSS and gene body regions.</p> <p>Download the GENCODE v49 GTF file:</p> <pre><code># Download GENCODE basic annotation (primary assembly)\nwget https://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_49/gencode.v49.primary_assembly.basic.annotation.gtf.gz\n\n# Decompress\ngunzip gencode.v49.primary_assembly.basic.annotation.gtf.gz\n</code></pre> <p>This GTF file contains comprehensive gene annotations including transcript start sites (TSS), gene bodies, and other genomic features.</p>"},{"location":"15_visualization_heatmaps/#step-2-extract-tss-regions-portrait-mode","title":"Step 2: Extract TSS Regions (Portrait Mode)","text":"<p>Run this <code>awk</code> script to get a 1bp position for every Transcript Start Site from the GTF:</p> <pre><code>awk 'BEGIN{OFS=\"\\t\"} $3==\"transcript\" {                 \n  if($7==\"+\")                                         \n    print $1, $4-1, $4, $12, \".\", $7;                \n  else                                               \n    print $1, $5-1, $5, $12, \".\", $7                 \n}' gencode.v49.annotation.gtf |  \ntr -d '\";' |                                        \nsort -k1,1V -k2,2n &gt; tss.bed                        \n</code></pre> <p>This command extracts the transcription start site (TSS) for each transcript from the GTF annotation file. The script identifies whether each transcript is on the forward (+) or reverse (-) strand: for forward-strand transcripts, the TSS is the start coordinate (column 4), while for reverse-strand transcripts, it's the end coordinate (column 5). . The output <code>tss.bed</code> is a BED file containing chromosome, TSS position (as a 1bp interval), transcript name, and strand information for every annotated transcript.</p>"},{"location":"15_visualization_heatmaps/#step-3-extract-gene-bodies-panorama-mode","title":"Step 3: Extract Gene Bodies (Panorama Mode)","text":"<p>Run this to get the full gene intervals from the same GTF file:</p> <pre><code>awk 'BEGIN{OFS=\"\\t\"} $3==\"gene\" {                     \n  print $1, $4-1, $5, $10, \".\", $7                    \n}' gencode.v49.annotation.gtf | \ntr -d '\";' |                                          \nsort -k1,1V -k2,2n &gt; genes.bed\n</code></pre>"},{"location":"15_visualization_heatmaps/#step-4-create-output-directories","title":"Step 4: Create Output Directories","text":"<pre><code># Create directories for matrices and plots\nmkdir -p deeptools_viz/matrices\nmkdir -p deeptools_viz/plots\n</code></pre>"},{"location":"15_visualization_heatmaps/#step-5-build-the-matrix-the-blueprint","title":"Step 5: Build the Matrix (The Blueprint)","text":"<p>This command calculates the coverage scores for plotting.</p> <p>Mode A: Reference-Point (TSS)</p> <pre><code>computeMatrix reference-point \\\n  --referencePoint TSS \\\n  -R tss.bed \\\n  -S \\\n    bigwigs/H3K9ac_ENCFF534IPX.bw \\\n    bigwigs/H3K9ac_ENCFF193NPE.bw \\\n  -b 3000 -a 3000 \\\n  --binSize 250 \\\n  --numberOfProcessors 4 \\\n  -o deeptools_viz/matrices/H3K9ac_TSS.mat.gz\n</code></pre> <p>Mode B: Scale-Regions (Gene Body)</p> <pre><code>computeMatrix scale-regions \\\n  -R genes.bed \\\n  -S \\\n    bigwigs/H3K9ac_ENCFF534IPX.bw \\\n    bigwigs/H3K9ac_ENCFF193NPE.bw \\\n  --regionBodyLength 5000 \\\n  -b 3000 -a 3000 \\\n  --binSize 250 \\\n  --numberOfProcessors 4 \\\n  -o deeptools_viz/matrices/H3K9ac_genes.mat.gz\n</code></pre>"},{"location":"15_visualization_heatmaps/#step-6-plotting-the-photo","title":"Step 6: Plotting (The Photo)","text":"<p>Now we turn the matrices into plots.</p> <pre><code>plotProfile \\\n  -m deeptools_viz/matrices/H3K9ac_TSS.mat.gz \\\n  --perGroup \\\n  -out deeptools_viz/plots/H3K9ac_TSS_profile.pdf\n</code></pre> <p>Generating plots for all samples:</p> <p>Repeat the above <code>computeMatrix</code> and <code>plotProfile</code> commands for all your samples (Input, H3K27me3, CEBPA) to create comprehensive visualization of ChIP-seq signal patterns.</p>"},{"location":"15_visualization_heatmaps/#reading-the-pictures","title":"Reading the Pictures","text":""},{"location":"15_visualization_heatmaps/#tss-centered-profiles-individual-replicates","title":"TSS-Centered Profiles: Individual Replicates","text":"<p>The following plots show average ChIP-seq signal around transcription start sites (TSS \u00b13 kb) for individual replicates of Input, H3K27me3, and H3K9ac:</p> <p></p> <p>Each panel shows average signal around transcription start sites (\u00b13 kb), and the differences between tracks are clear.</p> <p>The input tracks show low, smooth signal with no sharp peak at the TSS. This is what background looks like and confirms there is no real promoter-specific enrichment in the inputs.</p> <p>The H3K27me3 tracks show broader enrichment across the promoter region. The signal rises gradually toward the TSS and spreads over several kilobases, which fits a repressive chromatin mark that acts over domains rather than sharply at promoters.</p> <p>The H3K9ac tracks are very different. They show strong, narrow peaks centered exactly at the TSS, with signal far higher than all other tracks. This reflects active promoter-associated acetylation and clear separation from background.</p>"},{"location":"15_visualization_heatmaps/#tsstes-metagene-profiles-genome-wide-patterns","title":"TSS/TES Metagene Profiles: Genome-Wide Patterns","text":"<p>The following plots show average ChIP-seq signal across transcription start sites (TSS) and transcription end sites (TES):</p> <p></p> <p>The genome-wide metagene profiles show clear differences between input, CEBP, and histone marks across transcription start sites (TSS) and transcription end sites (TES).</p> <p>The input tracks show low-amplitude signal with mild structure around both TSS and TES, consistent with background chromatin features and technical biases rather than true enrichment. There is no sharp localization to either boundary.</p> <p>In contrast, H3K27me3 shows broad enrichment centered near the TSS that extends across the gene body and decays toward the TES. The signal is moderate in amplitude and spread over several kilobases, consistent with its role as a repressive chromatin mark acting over domains rather than forming sharp peaks.</p> <p>H3K9ac displays strong, sharp enrichment precisely at the TSS, with signal levels far exceeding input and transcription factor profiles. The signal decreases steadily across the gene body and approaches baseline near the TES, consistent with promoter-focused acetylation associated with active transcription.</p>"},{"location":"15_visualization_heatmaps/#average-signal-analysis","title":"Average Signal Analysis","text":"<p>These are individual replicates of the different IPs. Now let's see how they look cumulatively.</p>"},{"location":"15_visualization_heatmaps/#average-bigwigs","title":"Average BigWigs","text":"<p>To reduce noise and create consensus signal tracks, we average the replicate BigWig files for each mark:</p> <pre><code># Create output directory\nmkdir -p bw_mean\n\n# Average H3K9ac replicates\nbigwig Average -b bigwigs/H3K9ac_ENCFF193NPE.bw bigwigs/H3K9ac_ENCFF534IPX.bw \\\n  -o bw_mean/H3K9ac_mean.bw -p 6\n\n# Average H3K27me3 replicates\nbigwigAverage -b bigwigs/H3K27me3_ENCFF164ALR.bw bigwigs/H3K27me3_ENCFF532DQH.bw \\\n  -o bw_mean/H3K27me3_mean.bw -p 6\n\n# Average Input replicates\nbigwigAverage -b bigwigs/Input_ENCFF110SOB.bw bigwigs/Input_ENCFF919XCV.bw \\\n  -o bw_mean/Input_mean.bw -p 6\n</code></pre>"},{"location":"15_visualization_heatmaps/#normalization-to-input-controls","title":"Normalization to Input Controls","text":"<p>After averaging, we normalize IP signals to Input controls using log2 ratio to reveal true enrichment:</p> <pre><code># Create output directory\nmkdir -p bw_log2\n\n# Normalize H3K9ac to Input (log2 ratio)\nbigwigCompare -b1 bw_mean/H3K9ac_mean.bw -b2 bw_mean/Input_mean.bw \\\n  --operation log2 --pseudocount 1 -p 6 \\\n  -o bw_log2/H3K9ac_log2IPoverInput.bw\n\n# Normalize H3K27me3 to Input (log2 ratio)\nbigwigCompare -b1 bw_mean/H3K27me3_mean.bw -b2 bw_mean/Input_mean.bw \\\n  --operation log2 --pseudocount 1 -p 6 \\\n  -o bw_log2/H3K27me3_log2IPoverInput.bw\n</code></pre> <p>What is pseudocount?</p> <p>The <code>--pseudocount 1</code> parameter adds 1 to all signal values before calculating the log2 ratio. This prevents two critical mathematical problems:</p> <ol> <li>Division by zero: When Input signal is 0, we'd calculate log2(IP/0) which is undefined</li> <li>Log of zero: When IP signal is 0, we'd calculate log2(0/Input) which is also undefined</li> </ol> <p>By adding 1 to both values, we calculate <code>log2((IP+1)/(Input+1))</code> instead. This gives meaningful results even in regions with no signal while minimally affecting regions with strong signal (where adding 1 to large numbers like 100 has negligible impact).</p>"},{"location":"15_visualization_heatmaps/#visualization-with-normalized-data","title":"Visualization with Normalized Data","text":""},{"location":"15_visualization_heatmaps/#tss-centered-profile-with-log2ipinput","title":"TSS-Centered Profile with log2(IP/Input)","text":"<p>Create profile plots using the log2-normalized BigWig files:</p> <pre><code>computeMatrix reference-point \\\n  --referencePoint TSS \\\n  -b 3000 -a 3000 \\\n  --binSize 250 \\\n  -R tss.bed \\\n  -S bw_log2/H3K9ac_log2IPoverInput.bw \\\n  --skipZeros --missingDataAsZero \\\n  -p 6 \\\n  -o deeptools_viz/matrices/H3K9ac_TSS_log2.mat.gz\n\nplotProfile \\\n  -m deeptools_viz/matrices/H3K9ac_TSS_log2.mat.gz \\\n  --refPointLabel TSS \\\n  --yAxisLabel \"log2(IP/Input)\" \\\n  --plotTitle \"H3K9ac log2(IP/Input)\" \\\n  -out deeptools_viz/plots/H3K9ac_TSS_log2_profile.pdf\n</code></pre> <p></p>"},{"location":"15_visualization_heatmaps/#gene-body-profile-with-averaged-signal","title":"Gene Body Profile with Averaged Signal","text":"<p>Visualize signal across gene bodies using the averaged (non-normalized) BigWigs:</p> <pre><code>computeMatrix scale-regions \\\n  -b 3000 -a 3000 \\\n  --regionBodyLength 5000 \\\n  --binSize 250 \\\n  -R genes.bed \\\n  -S bw_mean/H3K9ac_mean.bw \\\n  --skipZeros --missingDataAsZero \\\n  -p 6 \\\n  -o deeptools_viz/matrices/H3K9ac_genes_mean.mat.gz\n\nplotProfile \\\n  -m deeptools_viz/matrices/H3K9ac_genes_mean.mat.gz \\\n  --yAxisLabel \"Average signal\" \\\n  --plotTitle \"H3K9ac gene-body (averaged replicates)\" \\\n  -out deeptools_viz/plots/H3K9ac_genes_profile.pdf\n</code></pre>"},{"location":"15_visualization_heatmaps/#cebpa-peak-focused-analysis","title":"CEBPA Peak-Focused Analysis","text":"<p>Now, to focus on peaks identified by MACS3 and validated by IDR, we'll identify promoters overlapping CEBPA consensus peaks.</p>"},{"location":"15_visualization_heatmaps/#step-1-identify-promoters-overlapping-cebpa-peaks","title":"Step 1: Identify Promoters Overlapping CEBPA Peaks","text":"<pre><code># Count total CEBPA IDR-passed peaks\nwc -l ceb_idr_passed.bed\n# Output: 9468 ceb_idr_passed.bed\n\n# Find promoters that overlap with CEBPA peaks\nbedtools intersect \\\n  -a tss.bed \\\n  -b ceb_idr_passed.bed \\\n  -u &gt; cebpa_peak_promoters.bed\n\nwc -l cebpa_peak_promoters.bed\n# Output: 5792 cebpa_peak_promoters.bed\n</code></pre> <p>This identifies 5,792 promoters (out of all TSS) that are bound by CEBPA.</p>"},{"location":"15_visualization_heatmaps/#step-2-create-tss-centered-heatmap-for-cebpa-bound-promoters","title":"Step 2: Create TSS-Centered Heatmap for CEBPA-Bound Promoters","text":"<pre><code># Compute matrix for CEBPA signal at CEBPA-bound promoters\ncomputeMatrix reference-point \\\n  --referencePoint TSS \\\n  -b 2000 -a 2000 \\\n  -R cebpa_peak_promoters.bed \\\n  -S bw_log2/ceb_log2IPoverInput.bw \\\n  --binSize 25 \\\n  --skipZeros \\\n  -p 8 \\\n  -o deeptools_viz/matrices/ceb_idr_TSS.mat.gz\n\n# Plot heatmap\nplotHeatmap \\\n  -m deeptools_viz/matrices/ceb_idr_TSS.mat.gz \\\n  --colorMap RdBu_r \\\n  --refPointLabel TSS \\\n  --dpi 600 \\\n  -out deeptools_viz/plots/cebpa_peakPromoters_heatmap.pdf\n</code></pre>"},{"location":"15_visualization_heatmaps/#heatmap-visualization","title":"Heatmap Visualization","text":""},{"location":"15_visualization_heatmaps/#step-3-chromatin-state-analysis-at-cebpa-bound-promoters","title":"Step 3: Chromatin State Analysis at CEBPA-Bound Promoters","text":"<p>Objective: Use the CEBPA-peak promoter bed file (<code>cebpa_peak_promoters.bed</code>) to identify enrichment of H3K9ac (active mark) and H3K27me3 (repressive mark) at CEBPA binding sites.</p> <pre><code># Compute matrix using CEBPA-peak promoters as regions\n# This shows H3K9ac and H3K27me3 enrichment at sites where CEBPA binds\ncomputeMatrix reference-point \\\n  --referencePoint TSS \\\n  -b 2000 -a 2000 \\\n  -R cebpa_peak_promoters.bed \\\n  -S bw_log2/ceb_log2IPoverInput.bw \\\n     bw_log2/H3K9ac_log2IPoverInput.bw \\\n     bw_log2/H3K27me3_log2IPoverInput.bw \\\n  --binSize 25 \\\n  -p 8 \\\n  -o deeptools_viz/matrices/cebpa_multimark_TSS.mat.gz\n\n# Profile plot: shows average enrichment across all CEBPA-bound promoters\nplotProfile \\\n  -m deeptools_viz/matrices/cebpa_multimark_TSS.mat.gz \\\n  --perGroup \\\n  --plotTitle \"CEBPA-bound promoters: Chromatin state\" \\\n  --dpi 600 \\\n  -out deeptools_viz/plots/cebpa_multimark_profile.pdf\n\n# Heatmap: shows enrichment at individual CEBPA-bound promoters\nplotHeatmap \\\n  -m deeptools_viz/matrices/cebpa_multimark_TSS.mat.gz \\\n  --colorMap RdBu_r \\\n  --dpi 600 \\\n  -out deeptools_viz/plots/cebpa_multimark_heatmap.pdf\n</code></pre> <p>What this reveals:</p> <ul> <li>H3K9ac enrichment at CEBPA peaks indicates active chromatin</li> <li>H3K27me3 depletion at CEBPA peaks confirms absence of repressive marks</li> <li>CEBPA binds preferentially to active (H3K9ac+, H3K27me3-) promoters</li> </ul>"},{"location":"15_visualization_heatmaps/#profile-plot","title":"Profile Plot","text":""},{"location":"15_visualization_heatmaps/#heatmap","title":"Heatmap","text":""},{"location":"15_visualization_heatmaps/#directory-structure-after-visualization","title":"Directory Structure After Visualization","text":"<pre><code>chipseq_tutorial/\n\u251c\u2500\u2500 bigwigs/                    \u2190 Normalized BigWig files from Tutorial 14\n\u251c\u2500\u2500 bw_mean/                    \u2190 **NEW: Averaged BigWig files**\n\u2502   \u251c\u2500\u2500 H3K9ac_mean.bw\n\u2502   \u251c\u2500\u2500 H3K27me3_mean.bw\n\u2502   \u2514\u2500\u2500 Input_mean.bw\n\u251c\u2500\u2500 bw_log2/                    \u2190 **NEW: Log2(IP/Input) normalized files**\n\u2502   \u251c\u2500\u2500 H3K9ac_log2IPoverInput.bw\n\u2502   \u2514\u2500\u2500 H3K27me3_log2IPoverInput.bw\n\u251c\u2500\u2500 deeptools_viz/              \u2190 **NEW: deepTools visualization outputs**\n\u2502   \u251c\u2500\u2500 matrices/               # Computed matrices\n\u2502   \u2502   \u251c\u2500\u2500 H3K9ac_TSS.mat.gz\n\u2502   \u2502   \u251c\u2500\u2500 H3K9ac_genes.mat.gz\n\u2502   \u2502   \u2514\u2500\u2500 cebpa_multimark_TSS.mat.gz\n\u2502   \u2514\u2500\u2500 plots/                  # Generated plots\n\u2502       \u251c\u2500\u2500 H3K9ac_TSS_profile.pdf\n\u2502       \u251c\u2500\u2500 H3K9ac_genes_profile.pdf\n\u2502       \u2514\u2500\u2500 cebpa_multimark_heatmap.pdf\n\u251c\u2500\u2500 tss.bed                     \u2190 **NEW: TSS annotation (1bp positions)**\n\u251c\u2500\u2500 genes.bed                   \u2190 **NEW: Gene body annotation**\n\u2514\u2500\u2500 cebpa_peak_promoters.bed    \u2190 **NEW: CEBPA-bound promoters**\n</code></pre>"},{"location":"15_visualization_heatmaps/#summary","title":"Summary","text":"<p>CEBPA-bound promoters are enriched for active chromatin (H3K9ac) and depleted for repressive chromatin (H3K27me3).</p>"},{"location":"16_chipseeker_annotation/","title":"Annotation &amp; Visualization","text":""},{"location":"16_chipseeker_annotation/#introduction-decoding-the-map","title":"Introduction: Decoding the Map","text":"<p>You have successfully defined your Peaks (GPS coordinates of protein binding). But coordinates alone don't tell a biological story. Annotation is the process of cross-referencing these coordinates with a Gene Map (GTF) to answer:</p> <ul> <li>\"Does my protein bind to Promoters?\"</li> <li>\"Is it hiding in Intergenic Deserts?\"</li> <li>\"Does it prefer Exons or Introns?\"</li> </ul> <p>Below is the full interactive report generated by ChIPseeker.</p>"},{"location":"16_chipseeker_annotation/#how-to-interpret-the-figures-reference-guide","title":"How to Interpret the Figures (Reference Guide)","text":"<p>Since the report above contains many plots, here is a guide on how to read the most important ones:</p>"},{"location":"16_chipseeker_annotation/#1-the-tss-heatmap-portrait-mode","title":"1. The TSS Heatmap (Portrait Mode)","text":"<ul> <li>What it shows: The binding intensity \u00b13000bp around the Transcription Start Site (TSS).</li> <li>How to read it:</li> <li>Vertical Axis: Each line is one gene.</li> <li>Horizontal Axis: Center is TSS. Left is Upstream, Right is Downstream.</li> <li>Key Insight: A dark vertical stripe at the center (0) means your protein is a Strong Promoter Binder (like H3K9ac or Transcription Factors). A broad cloud means it's a domain mark (like H3K27me3).</li> </ul>"},{"location":"16_chipseeker_annotation/#2-the-average-profile-plot","title":"2. The Average Profile Plot","text":"<ul> <li>What it shows: The average signal across all genes, summarized as a line graph.</li> <li>How to read it:</li> <li>Sharp Spike at 0: Confirms precise positioning at promoters.</li> <li>Dip (Valley) at 0: Indicates the protein binds around the TSS (like nucleosomes) but leaves the start site open.</li> </ul>"},{"location":"16_chipseeker_annotation/#3-the-genomic-annotation-barplot","title":"3. The Genomic Annotation Barplot","text":"<ul> <li>What it shows: Where your peaks land (Promoter vs. Intron vs. Distal Intergenic).</li> <li>How to read it:</li> <li>High Promoter Fraction (&gt;50%): Your protein regulates genes directly (e.g., TFs, active histones).</li> <li>High Distal Intergenic: Your protein might be an Enhancer-binding factor.</li> </ul>"},{"location":"CONTRIBUTORS/","title":"Contributors","text":"<p>This ChIP-seq Analysis Tutorial series was developed and is maintained by:</p> <p>Raja Ishaq Nabi Khan Epigenetics Researcher Research Focus: RNA Modifications &amp; Epigenetics</p> <p></p>"},{"location":"CONTRIBUTORS/#acknowledgments","title":"Acknowledgments","text":"<p>This tutorial is informed by experimental standards and analytical guidelines established by the ENCODE Consortium and makes extensive use of established open-source tools, including MACS3, HOMER, deepTools, and IDR. Publicly available ChIP-seq datasets (including SRP115709) were used for demonstration, benchmarking, and validation.</p>"},{"location":"CONTRIBUTORS/#contributing","title":"Contributing","text":"<p>Contributions are welcome. To contribute:</p> <ol> <li>Fork the repository</li> <li>Create a feature branch</li> <li>Submit a pull request with a clear description of the changes</li> </ol> <p>Bug fixes, corrections, and documentation improvements are particularly encouraged.</p>"},{"location":"CONTRIBUTORS/#ai-usage-disclosure","title":"AI Usage Disclosure","text":"<p>AI tools were used in a limited, assistive capacity for script troubleshooting, installation guidance, and documentation consistency.</p>"},{"location":"CONTRIBUTORS/#citation","title":"Citation","text":"<p>If you use this tutorial in research or teaching, please cite the archived version:</p> <p>Khan, R. I. N. (2025). ChIP-seq Analysis Tutorial: A Practical Guide to Chromatin Immunoprecipitation Sequencing Data Analysis (Version 1.0) [Software]. Zenodo. https://doi.org/10.5281/zenodo.XXXXXXX</p>"},{"location":"CONTRIBUTORS/#license","title":"License","text":"<p>This project is distributed under the MIT License. See the LICENSE file for details.</p> <p>Last updated: December 2025 Version: 1.0</p>"},{"location":"SUMMARY/","title":"Summary","text":"<ul> <li>Welcome</li> <li>Setup Environment</li> <li>Bash Automation</li> <li>GEO Fastq Download</li> <li>Fastq Concepts</li> <li>Alignment with Bowtie2</li> <li>Duplicate Removal &amp; QC</li> <li>Library Complexity</li> <li>BAM Quality Metrics</li> <li>Strand Cross Correlation</li> <li>BAM Summary &amp; Fingerprint</li> <li>MACS3 Peak Calling</li> <li>Quality Metrics - FRiP</li> <li>Reproducibility Analysis (IDR)</li> <li>BigWig Generation</li> <li>Visualization Heatmaps</li> <li>Annotation with ChIPseeker</li> <li>Appendix: How We Built This Book</li> </ul> <ul> <li>Contributors</li> </ul>"}]}